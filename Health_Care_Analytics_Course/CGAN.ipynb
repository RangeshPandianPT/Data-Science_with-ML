{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134fbb53-8f2b-404d-bfb5-3f0faf2e6cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SIVAKUMAR S\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\SIVAKUMAR S\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to C:\\Users\\SIVAKUMAR S/.cache\\torch\\hub\\checkpoints\\inception_v3_google-0cc3c7bd.pth\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 104M/104M [01:29<00:00, 1.21MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 | G: 0.9232 | D: 0.5451 | IS: 1.03 | FID: 399.04\n",
      "Epoch 2/200 | G: 1.0297 | D: 0.5442 | IS: 1.06 | FID: 272.56\n",
      "Epoch 3/200 | G: 1.0691 | D: 0.5369 | IS: 1.04 | FID: 224.45\n",
      "Epoch 4/200 | G: 1.2064 | D: 0.5045 | IS: 1.04 | FID: 214.42\n",
      "Epoch 5/200 | G: 1.2714 | D: 0.4838 | IS: 1.04 | FID: 202.01\n",
      "Epoch 6/200 | G: 1.2769 | D: 0.4830 | IS: 1.04 | FID: 214.04\n",
      "Epoch 7/200 | G: 1.2815 | D: 0.4824 | IS: 1.04 | FID: 206.08\n",
      "Epoch 8/200 | G: 1.3081 | D: 0.4767 | IS: 1.03 | FID: 200.24\n",
      "Epoch 9/200 | G: 1.3840 | D: 0.4600 | IS: 1.04 | FID: 207.66\n",
      "Epoch 10/200 | G: 1.4197 | D: 0.4544 | IS: 1.06 | FID: 210.45\n",
      "Epoch 11/200 | G: 1.5013 | D: 0.4260 | IS: 1.04 | FID: 194.64\n",
      "Epoch 12/200 | G: 1.5301 | D: 0.4181 | IS: 1.05 | FID: 182.38\n",
      "Epoch 13/200 | G: 1.5650 | D: 0.4078 | IS: 1.05 | FID: 182.87\n",
      "Epoch 14/200 | G: 1.6054 | D: 0.4108 | IS: 1.05 | FID: 193.61\n",
      "Epoch 15/200 | G: 1.6792 | D: 0.3859 | IS: 1.05 | FID: 177.77\n",
      "Epoch 16/200 | G: 1.6341 | D: 0.3986 | IS: 1.04 | FID: 178.01\n",
      "Epoch 17/200 | G: 1.7132 | D: 0.3801 | IS: 1.04 | FID: 180.78\n",
      "Epoch 18/200 | G: 1.7347 | D: 0.3738 | IS: 1.05 | FID: 170.95\n",
      "Epoch 19/200 | G: 1.7732 | D: 0.3640 | IS: 1.05 | FID: 172.13\n",
      "Epoch 20/200 | G: 1.7735 | D: 0.3720 | IS: 1.06 | FID: 186.70\n",
      "Epoch 21/200 | G: 1.9112 | D: 0.3383 | IS: 1.05 | FID: 189.40\n",
      "Epoch 22/200 | G: 1.9234 | D: 0.3450 | IS: 1.05 | FID: 180.65\n",
      "Epoch 23/200 | G: 1.8798 | D: 0.3433 | IS: 1.05 | FID: 166.53\n",
      "Epoch 24/200 | G: 1.8969 | D: 0.3463 | IS: 1.04 | FID: 167.93\n",
      "Epoch 25/200 | G: 1.9558 | D: 0.3481 | IS: 1.04 | FID: 145.60\n",
      "Epoch 26/200 | G: 1.9514 | D: 0.3294 | IS: 1.05 | FID: 171.58\n",
      "Epoch 27/200 | G: 1.9582 | D: 0.3283 | IS: 1.07 | FID: 177.25\n",
      "Epoch 28/200 | G: 2.0350 | D: 0.3310 | IS: 1.03 | FID: 179.59\n",
      "Epoch 29/200 | G: 2.0258 | D: 0.3243 | IS: 1.06 | FID: 190.22\n",
      "Epoch 30/200 | G: 2.0849 | D: 0.2993 | IS: 1.05 | FID: 169.48\n",
      "Epoch 31/200 | G: 2.1077 | D: 0.3056 | IS: 1.04 | FID: 158.28\n",
      "Epoch 32/200 | G: 2.1046 | D: 0.3109 | IS: 1.06 | FID: 164.16\n",
      "Epoch 33/200 | G: 2.1095 | D: 0.3073 | IS: 1.05 | FID: 166.39\n",
      "Epoch 34/200 | G: 2.1218 | D: 0.3097 | IS: 1.04 | FID: 183.14\n",
      "Epoch 35/200 | G: 2.1428 | D: 0.3162 | IS: 1.04 | FID: 173.27\n",
      "Epoch 36/200 | G: 2.0949 | D: 0.3148 | IS: 1.04 | FID: 162.34\n",
      "Epoch 37/200 | G: 2.1138 | D: 0.3193 | IS: 1.03 | FID: 183.00\n",
      "Epoch 38/200 | G: 2.1944 | D: 0.2976 | IS: 1.04 | FID: 175.82\n",
      "Epoch 39/200 | G: 2.2106 | D: 0.3158 | IS: 1.05 | FID: 171.68\n",
      "Epoch 40/200 | G: 2.2439 | D: 0.2969 | IS: 1.06 | FID: 170.65\n",
      "Epoch 41/200 | G: 2.2663 | D: 0.3009 | IS: 1.05 | FID: 167.91\n",
      "Epoch 42/200 | G: 2.2386 | D: 0.3123 | IS: 1.06 | FID: 166.77\n",
      "Epoch 43/200 | G: 2.2387 | D: 0.3143 | IS: 1.05 | FID: 153.04\n",
      "Epoch 44/200 | G: 2.2205 | D: 0.2942 | IS: 1.05 | FID: 157.04\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "# =============================\n",
    "# Configuration (Jupyter-safe)\n",
    "# =============================\n",
    "class Opt:\n",
    "    n_epochs = 200\n",
    "    batch_size = 64\n",
    "    lr = 0.0002\n",
    "    b1 = 0.5\n",
    "    b2 = 0.999\n",
    "    latent_dim = 100\n",
    "    n_classes = 10\n",
    "    img_size = 28\n",
    "    channels = 1\n",
    "    sample_interval = 500\n",
    "\n",
    "opt = Opt()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "img_shape = (opt.channels, opt.img_size, opt.img_size)\n",
    "\n",
    "os.makedirs(\"results/images\", exist_ok=True)\n",
    "os.makedirs(\"results/plots\", exist_ok=True)\n",
    "\n",
    "# =============================\n",
    "# Generator (Conditional)\n",
    "# =============================\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.label_emb = nn.Embedding(opt.n_classes, opt.n_classes)\n",
    "\n",
    "        def block(in_f, out_f, norm=True):\n",
    "            layers = [nn.Linear(in_f, out_f)]\n",
    "            if norm:\n",
    "                layers.append(nn.BatchNorm1d(out_f))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(opt.latent_dim + opt.n_classes, 128, False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z, labels):\n",
    "        x = torch.cat((z, self.label_emb(labels)), dim=1)\n",
    "        img = self.model(x)\n",
    "        return img.view(img.size(0), *img_shape)\n",
    "\n",
    "# =============================\n",
    "# Discriminator (Conditional)\n",
    "# =============================\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.label_emb = nn.Embedding(opt.n_classes, opt.n_classes)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(opt.n_classes + int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        d_in = torch.cat((img.view(img.size(0), -1), self.label_emb(labels)), dim=1)\n",
    "        return self.model(d_in)\n",
    "\n",
    "# =============================\n",
    "# Models & Loss\n",
    "# =============================\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "\n",
    "# =============================\n",
    "# Data\n",
    "# =============================\n",
    "dataloader = DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"./data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.Resize(opt.img_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5])\n",
    "        ])\n",
    "    ),\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# =============================\n",
    "# Feature Extractor (Inception)\n",
    "# =============================\n",
    "inception = models.inception_v3(pretrained=True, transform_input=False).to(device)\n",
    "inception.eval()\n",
    "inception.fc = nn.Identity()\n",
    "\n",
    "def get_features(images):\n",
    "    images = images.repeat(1, 3, 1, 1)\n",
    "    images = nn.functional.interpolate(images, size=299)\n",
    "    with torch.no_grad():\n",
    "        return inception(images).cpu().numpy()\n",
    "\n",
    "# =============================\n",
    "# Metrics\n",
    "# =============================\n",
    "def inception_score(features, splits=10):\n",
    "    scores = []\n",
    "    N = features.shape[0]\n",
    "    for i in range(splits):\n",
    "        part = features[i * (N // splits):(i + 1) * (N // splits)]\n",
    "        p_yx = np.exp(part) / np.sum(np.exp(part), axis=1, keepdims=True)\n",
    "        p_y = np.mean(p_yx, axis=0)\n",
    "        kl = p_yx * (np.log(p_yx + 1e-10) - np.log(p_y + 1e-10))\n",
    "        scores.append(np.exp(np.mean(np.sum(kl, axis=1))))\n",
    "    return np.mean(scores)\n",
    "\n",
    "def fid_score(real_f, fake_f):\n",
    "    mu1, sigma1 = real_f.mean(axis=0), np.cov(real_f, rowvar=False)\n",
    "    mu2, sigma2 = fake_f.mean(axis=0), np.cov(fake_f, rowvar=False)\n",
    "    covmean = sqrtm(sigma1 @ sigma2)\n",
    "    return np.real(np.sum((mu1 - mu2) ** 2) + np.trace(sigma1 + sigma2 - 2 * covmean))\n",
    "\n",
    "# =============================\n",
    "# Training\n",
    "# =============================\n",
    "g_losses, d_losses, fid_scores, is_scores = [], [], [], []\n",
    "\n",
    "for epoch in range(opt.n_epochs):\n",
    "\n",
    "    g_epoch, d_epoch = 0, 0\n",
    "    real_imgs_all, fake_imgs_all = [], []\n",
    "\n",
    "    for imgs, labels in dataloader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        batch = imgs.size(0)\n",
    "\n",
    "        valid = torch.ones(batch, 1, device=device)\n",
    "        fake = torch.zeros(batch, 1, device=device)\n",
    "\n",
    "        # ---- Generator ----\n",
    "        optimizer_G.zero_grad()\n",
    "        z = torch.randn(batch, opt.latent_dim, device=device)\n",
    "        gen_labels = torch.randint(0, opt.n_classes, (batch,), device=device)\n",
    "        gen_imgs = generator(z, gen_labels)\n",
    "        g_loss = criterion(discriminator(gen_imgs, gen_labels), valid)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---- Discriminator ----\n",
    "        optimizer_D.zero_grad()\n",
    "        real_loss = criterion(discriminator(imgs, labels), valid)\n",
    "        fake_loss = criterion(discriminator(gen_imgs.detach(), gen_labels), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        g_epoch += g_loss.item()\n",
    "        d_epoch += d_loss.item()\n",
    "\n",
    "        real_imgs_all.append(imgs)\n",
    "        fake_imgs_all.append(gen_imgs)\n",
    "\n",
    "    # ---- Epoch metrics ----\n",
    "    real_imgs_all = torch.cat(real_imgs_all)[:1000]\n",
    "    fake_imgs_all = torch.cat(fake_imgs_all)[:1000]\n",
    "\n",
    "    real_feat = get_features(real_imgs_all)\n",
    "    fake_feat = get_features(fake_imgs_all)\n",
    "\n",
    "    fid = fid_score(real_feat, fake_feat)\n",
    "    inc = inception_score(fake_feat)\n",
    "\n",
    "    g_losses.append(g_epoch / len(dataloader))\n",
    "    d_losses.append(d_epoch / len(dataloader))\n",
    "    fid_scores.append(fid)\n",
    "    is_scores.append(inc)\n",
    "\n",
    "    # ---- Save image comparison ----\n",
    "    comparison = torch.cat([real_imgs_all[:25], fake_imgs_all[:25]])\n",
    "    save_image(comparison, f\"results/images/epoch_{epoch+1}.png\", nrow=5, normalize=True)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{opt.n_epochs} | G: {g_losses[-1]:.4f} | D: {d_losses[-1]:.4f} | IS: {inc:.2f} | FID: {fid:.2f}\")\n",
    "\n",
    "# =============================\n",
    "# Visualizations\n",
    "# =============================\n",
    "plt.figure()\n",
    "plt.plot(g_losses, label=\"G Loss\")\n",
    "plt.plot(d_losses, label=\"D Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss Curves\")\n",
    "plt.savefig(\"results/plots/loss_curve.png\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(is_scores)\n",
    "plt.title(\"Inception Score vs Epoch\")\n",
    "plt.savefig(\"results/plots/is_curve.png\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fid_scores)\n",
    "plt.title(\"FID vs Epoch\")\n",
    "plt.savefig(\"results/plots/fid_curve.png\")\n",
    "\n",
    "# PCA visualization\n",
    "pca = PCA(n_components=2)\n",
    "real_pca = pca.fit_transform(real_feat)\n",
    "fake_pca = pca.transform(fake_feat)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(real_pca[:, 0], real_pca[:, 1], alpha=0.5, label=\"Real\")\n",
    "plt.scatter(fake_pca[:, 0], fake_pca[:, 1], alpha=0.5, label=\"Fake\")\n",
    "plt.legend()\n",
    "plt.title(\"PCA Feature Space\")\n",
    "plt.savefig(\"results/plots/pca_real_fake.png\")\n",
    "\n",
    "print(\"Training and evaluation completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
