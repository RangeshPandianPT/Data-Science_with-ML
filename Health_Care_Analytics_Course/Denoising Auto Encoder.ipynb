{"cells":[{"cell_type":"code","execution_count":3,"id":"d293d434-c7f4-4965-ac72-d2b2b59731ec","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d293d434-c7f4-4965-ac72-d2b2b59731ec","executionInfo":{"status":"ok","timestamp":1768041697485,"user_tz":-330,"elapsed":866779,"user":{"displayName":"Sivakumar S","userId":"04332186060573251169"}},"outputId":"835aa15c-5fdf-4dc3-bfd3-16da46bb4f5b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","\n","==================================================\n","Training DAE with gaussian noise, Latent Dim: 32\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.91M/9.91M [00:00<00:00, 16.5MB/s]\n","100%|██████████| 28.9k/28.9k [00:00<00:00, 427kB/s]\n","100%|██████████| 1.65M/1.65M [00:00<00:00, 3.96MB/s]\n","100%|██████████| 4.54k/4.54k [00:00<00:00, 12.9MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/50]  Time: 9.58s  Loss: 0.0547  Test MSE: 0.0353  PSNR: 14.53dB\n","Epoch [2/50]  Time: 8.67s  Loss: 0.0306  Test MSE: 0.0269  PSNR: 15.70dB\n","Epoch [3/50]  Time: 8.73s  Loss: 0.0247  Test MSE: 0.0226  PSNR: 16.46dB\n","Epoch [4/50]  Time: 8.81s  Loss: 0.0215  Test MSE: 0.0202  PSNR: 16.96dB\n","Epoch [5/50]  Time: 8.98s  Loss: 0.0197  Test MSE: 0.0189  PSNR: 17.24dB\n","Epoch [6/50]  Time: 8.71s  Loss: 0.0185  Test MSE: 0.0175  PSNR: 17.56dB\n","Epoch [7/50]  Time: 8.69s  Loss: 0.0176  Test MSE: 0.0168  PSNR: 17.75dB\n","Epoch [8/50]  Time: 8.43s  Loss: 0.0168  Test MSE: 0.0165  PSNR: 17.83dB\n","Epoch [9/50]  Time: 8.46s  Loss: 0.0163  Test MSE: 0.0159  PSNR: 17.99dB\n","Epoch [10/50]  Time: 8.67s  Loss: 0.0157  Test MSE: 0.0154  PSNR: 18.14dB\n","Epoch [11/50]  Time: 8.74s  Loss: 0.0154  Test MSE: 0.0150  PSNR: 18.24dB\n","Epoch [12/50]  Time: 8.03s  Loss: 0.0150  Test MSE: 0.0149  PSNR: 18.27dB\n","Epoch [13/50]  Time: 8.77s  Loss: 0.0147  Test MSE: 0.0144  PSNR: 18.41dB\n","Epoch [14/50]  Time: 8.67s  Loss: 0.0145  Test MSE: 0.0142  PSNR: 18.48dB\n","Epoch [15/50]  Time: 8.42s  Loss: 0.0142  Test MSE: 0.0139  PSNR: 18.56dB\n","Epoch [16/50]  Time: 8.46s  Loss: 0.0140  Test MSE: 0.0138  PSNR: 18.61dB\n","Epoch [17/50]  Time: 8.71s  Loss: 0.0138  Test MSE: 0.0137  PSNR: 18.63dB\n","Epoch [18/50]  Time: 8.77s  Loss: 0.0136  Test MSE: 0.0137  PSNR: 18.65dB\n","Epoch [19/50]  Time: 8.08s  Loss: 0.0135  Test MSE: 0.0134  PSNR: 18.74dB\n","Epoch [20/50]  Time: 8.72s  Loss: 0.0134  Test MSE: 0.0135  PSNR: 18.70dB\n","Epoch [21/50]  Time: 8.71s  Loss: 0.0133  Test MSE: 0.0133  PSNR: 18.75dB\n","Epoch [22/50]  Time: 8.26s  Loss: 0.0132  Test MSE: 0.0131  PSNR: 18.84dB\n","Epoch [23/50]  Time: 8.55s  Loss: 0.0131  Test MSE: 0.0132  PSNR: 18.80dB\n","Epoch [24/50]  Time: 8.76s  Loss: 0.0130  Test MSE: 0.0129  PSNR: 18.90dB\n","Epoch [25/50]  Time: 8.78s  Loss: 0.0129  Test MSE: 0.0129  PSNR: 18.90dB\n","Epoch [26/50]  Time: 8.23s  Loss: 0.0128  Test MSE: 0.0130  PSNR: 18.88dB\n","Epoch [27/50]  Time: 8.66s  Loss: 0.0127  Test MSE: 0.0128  PSNR: 18.93dB\n","Epoch [28/50]  Time: 8.72s  Loss: 0.0127  Test MSE: 0.0128  PSNR: 18.92dB\n","Epoch [29/50]  Time: 8.46s  Loss: 0.0126  Test MSE: 0.0127  PSNR: 18.96dB\n","Epoch [30/50]  Time: 8.49s  Loss: 0.0126  Test MSE: 0.0128  PSNR: 18.91dB\n","Epoch [31/50]  Time: 8.64s  Loss: 0.0125  Test MSE: 0.0126  PSNR: 19.00dB\n","Epoch [32/50]  Time: 8.70s  Loss: 0.0125  Test MSE: 0.0125  PSNR: 19.03dB\n","Epoch [33/50]  Time: 8.07s  Loss: 0.0124  Test MSE: 0.0125  PSNR: 19.04dB\n","Epoch [34/50]  Time: 8.67s  Loss: 0.0124  Test MSE: 0.0125  PSNR: 19.04dB\n","Epoch [35/50]  Time: 8.63s  Loss: 0.0123  Test MSE: 0.0125  PSNR: 19.02dB\n","Epoch [36/50]  Time: 8.01s  Loss: 0.0123  Test MSE: 0.0124  PSNR: 19.08dB\n","Epoch [37/50]  Time: 8.64s  Loss: 0.0122  Test MSE: 0.0124  PSNR: 19.06dB\n","Epoch [38/50]  Time: 8.63s  Loss: 0.0122  Test MSE: 0.0122  PSNR: 19.12dB\n","Epoch [39/50]  Time: 8.74s  Loss: 0.0122  Test MSE: 0.0124  PSNR: 19.08dB\n","Epoch [40/50]  Time: 8.05s  Loss: 0.0121  Test MSE: 0.0122  PSNR: 19.12dB\n","Epoch [41/50]  Time: 8.64s  Loss: 0.0121  Test MSE: 0.0123  PSNR: 19.09dB\n","Epoch [42/50]  Time: 8.70s  Loss: 0.0121  Test MSE: 0.0122  PSNR: 19.15dB\n","Epoch [43/50]  Time: 8.05s  Loss: 0.0120  Test MSE: 0.0122  PSNR: 19.13dB\n","Epoch [44/50]  Time: 8.63s  Loss: 0.0120  Test MSE: 0.0123  PSNR: 19.12dB\n","Epoch [45/50]  Time: 8.64s  Loss: 0.0120  Test MSE: 0.0122  PSNR: 19.13dB\n","Epoch [46/50]  Time: 8.43s  Loss: 0.0120  Test MSE: 0.0122  PSNR: 19.14dB\n","Epoch [47/50]  Time: 8.35s  Loss: 0.0119  Test MSE: 0.0121  PSNR: 19.19dB\n","Epoch [48/50]  Time: 8.62s  Loss: 0.0120  Test MSE: 0.0121  PSNR: 19.16dB\n","Epoch [49/50]  Time: 8.63s  Loss: 0.0119  Test MSE: 0.0121  PSNR: 19.18dB\n","Epoch [50/50]  Time: 8.04s  Loss: 0.0119  Test MSE: 0.0121  PSNR: 19.19dB\n","\n","==================================================\n","Training DAE with salt_pepper noise, Latent Dim: 32\n","==================================================\n","Epoch [1/50]  Time: 8.54s  Loss: 0.0449  Test MSE: 0.0254  PSNR: 15.95dB\n","Epoch [2/50]  Time: 8.63s  Loss: 0.0212  Test MSE: 0.0176  PSNR: 17.55dB\n","Epoch [3/50]  Time: 8.81s  Loss: 0.0161  Test MSE: 0.0142  PSNR: 18.47dB\n","Epoch [4/50]  Time: 8.14s  Loss: 0.0139  Test MSE: 0.0128  PSNR: 18.92dB\n","Epoch [5/50]  Time: 8.68s  Loss: 0.0125  Test MSE: 0.0117  PSNR: 19.31dB\n","Epoch [6/50]  Time: 8.76s  Loss: 0.0115  Test MSE: 0.0111  PSNR: 19.56dB\n","Epoch [7/50]  Time: 8.44s  Loss: 0.0108  Test MSE: 0.0104  PSNR: 19.83dB\n","Epoch [8/50]  Time: 8.45s  Loss: 0.0103  Test MSE: 0.0102  PSNR: 19.91dB\n","Epoch [9/50]  Time: 8.67s  Loss: 0.0098  Test MSE: 0.0096  PSNR: 20.20dB\n","Epoch [10/50]  Time: 8.87s  Loss: 0.0094  Test MSE: 0.0093  PSNR: 20.34dB\n","Epoch [11/50]  Time: 8.14s  Loss: 0.0091  Test MSE: 0.0090  PSNR: 20.47dB\n","Epoch [12/50]  Time: 8.68s  Loss: 0.0089  Test MSE: 0.0088  PSNR: 20.56dB\n","Epoch [13/50]  Time: 8.75s  Loss: 0.0087  Test MSE: 0.0086  PSNR: 20.64dB\n","Epoch [14/50]  Time: 8.47s  Loss: 0.0085  Test MSE: 0.0085  PSNR: 20.72dB\n","Epoch [15/50]  Time: 8.45s  Loss: 0.0083  Test MSE: 0.0084  PSNR: 20.75dB\n","Epoch [16/50]  Time: 8.74s  Loss: 0.0082  Test MSE: 0.0082  PSNR: 20.87dB\n","Epoch [17/50]  Time: 8.79s  Loss: 0.0081  Test MSE: 0.0082  PSNR: 20.88dB\n","Epoch [18/50]  Time: 9.02s  Loss: 0.0079  Test MSE: 0.0080  PSNR: 20.96dB\n","Epoch [19/50]  Time: 8.64s  Loss: 0.0079  Test MSE: 0.0080  PSNR: 20.97dB\n","Epoch [20/50]  Time: 8.75s  Loss: 0.0077  Test MSE: 0.0078  PSNR: 21.11dB\n","Epoch [21/50]  Time: 8.88s  Loss: 0.0077  Test MSE: 0.0078  PSNR: 21.08dB\n","Epoch [22/50]  Time: 8.17s  Loss: 0.0076  Test MSE: 0.0080  PSNR: 20.99dB\n","Epoch [23/50]  Time: 8.72s  Loss: 0.0075  Test MSE: 0.0076  PSNR: 21.19dB\n","Epoch [24/50]  Time: 8.85s  Loss: 0.0075  Test MSE: 0.0076  PSNR: 21.21dB\n","Epoch [25/50]  Time: 8.46s  Loss: 0.0074  Test MSE: 0.0077  PSNR: 21.16dB\n","Epoch [26/50]  Time: 8.57s  Loss: 0.0073  Test MSE: 0.0076  PSNR: 21.19dB\n","Epoch [27/50]  Time: 8.79s  Loss: 0.0073  Test MSE: 0.0075  PSNR: 21.23dB\n","Epoch [28/50]  Time: 8.83s  Loss: 0.0072  Test MSE: 0.0074  PSNR: 21.32dB\n","Epoch [29/50]  Time: 8.16s  Loss: 0.0072  Test MSE: 0.0074  PSNR: 21.30dB\n","Epoch [30/50]  Time: 8.70s  Loss: 0.0072  Test MSE: 0.0074  PSNR: 21.32dB\n","Epoch [31/50]  Time: 8.79s  Loss: 0.0071  Test MSE: 0.0073  PSNR: 21.36dB\n","Epoch [32/50]  Time: 8.56s  Loss: 0.0071  Test MSE: 0.0073  PSNR: 21.36dB\n","Epoch [33/50]  Time: 8.34s  Loss: 0.0070  Test MSE: 0.0074  PSNR: 21.32dB\n","Epoch [34/50]  Time: 8.75s  Loss: 0.0070  Test MSE: 0.0072  PSNR: 21.43dB\n","Epoch [35/50]  Time: 8.82s  Loss: 0.0070  Test MSE: 0.0072  PSNR: 21.45dB\n","Epoch [36/50]  Time: 8.16s  Loss: 0.0069  Test MSE: 0.0072  PSNR: 21.44dB\n","Epoch [37/50]  Time: 8.67s  Loss: 0.0069  Test MSE: 0.0072  PSNR: 21.42dB\n","Epoch [38/50]  Time: 8.70s  Loss: 0.0069  Test MSE: 0.0071  PSNR: 21.48dB\n","Epoch [39/50]  Time: 8.57s  Loss: 0.0068  Test MSE: 0.0072  PSNR: 21.44dB\n","Epoch [40/50]  Time: 8.19s  Loss: 0.0068  Test MSE: 0.0072  PSNR: 21.46dB\n","Epoch [41/50]  Time: 8.67s  Loss: 0.0068  Test MSE: 0.0071  PSNR: 21.48dB\n","Epoch [42/50]  Time: 8.72s  Loss: 0.0068  Test MSE: 0.0071  PSNR: 21.49dB\n","Epoch [43/50]  Time: 8.09s  Loss: 0.0068  Test MSE: 0.0071  PSNR: 21.49dB\n","Epoch [44/50]  Time: 8.68s  Loss: 0.0067  Test MSE: 0.0071  PSNR: 21.50dB\n","Epoch [45/50]  Time: 8.73s  Loss: 0.0067  Test MSE: 0.0071  PSNR: 21.51dB\n","Epoch [46/50]  Time: 8.53s  Loss: 0.0067  Test MSE: 0.0070  PSNR: 21.55dB\n","Epoch [47/50]  Time: 8.29s  Loss: 0.0067  Test MSE: 0.0070  PSNR: 21.54dB\n","Epoch [48/50]  Time: 8.67s  Loss: 0.0067  Test MSE: 0.0069  PSNR: 21.60dB\n","Epoch [49/50]  Time: 8.70s  Loss: 0.0066  Test MSE: 0.0070  PSNR: 21.55dB\n","Epoch [50/50]  Time: 8.04s  Loss: 0.0066  Test MSE: 0.0069  PSNR: 21.59dB\n","\n","DAE Training and evaluation complete!\n","Results saved in the 'results' directory\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from pytorch_msssim import ssim\n","import os\n","from datetime import datetime\n","import time\n","import numpy as np\n","\n","# Set device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")\n","\n","# =============================================\n","# 1. DAE Model Definitions\n","# =============================================\n","\n","class Encoder(nn.Module):\n","    def __init__(self, latent_dim=32):  # Increased latent dim for better denoising\n","        super(Encoder, self).__init__()\n","        self.encoder = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, latent_dim)\n","        )\n","\n","    def forward(self, x):\n","        return self.encoder(x)\n","\n","class Decoder(nn.Module):\n","    def __init__(self, latent_dim=32):\n","        super(Decoder, self).__init__()\n","        self.decoder = nn.Sequential(\n","            nn.Linear(latent_dim, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 28*28),\n","            nn.Sigmoid(),\n","            nn.Unflatten(1, (1, 28, 28))\n","        )\n","\n","    def forward(self, z):\n","        return self.decoder(z)\n","\n","# =============================================\n","# 2. Noise Functions\n","# =============================================\n","\n","def add_gaussian_noise(images, noise_factor=0.5):\n","    \"\"\"Add Gaussian noise to images\"\"\"\n","    noisy = images + torch.randn_like(images) * noise_factor\n","    return torch.clamp(noisy, 0., 1.)\n","\n","def add_salt_pepper_noise(images, prob=0.1):\n","    \"\"\"Add salt and pepper noise to images\"\"\"\n","    mask = torch.rand_like(images) < prob\n","    salt = torch.rand_like(images) > 0.5\n","    noisy = images.clone()\n","    noisy[mask] = salt[mask].float()\n","    return noisy\n","\n","# =============================================\n","# 3. DAE Training Function\n","# =============================================\n","\n","def train_dae(epochs=50, batch_size=128, latent_dim=32, noise_type='gaussian'):\n","    # Create results directory\n","    os.makedirs('results', exist_ok=True)\n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    excel_filename = f'results/dae_metrics_{noise_type}_{timestamp}.xlsx'\n","    writer = pd.ExcelWriter(excel_filename, engine='openpyxl')\n","\n","    # Load data\n","    transform = transforms.Compose([transforms.ToTensor()])\n","    train_data = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n","    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","    test_data = datasets.MNIST(root=\"./data\", train=False, transform=transform)\n","    test_loader = DataLoader(test_data, batch_size=128, shuffle=True)\n","\n","    # Initialize models\n","    encoder = Encoder(latent_dim).to(device)\n","    decoder = Decoder(latent_dim).to(device)\n","\n","    # Optimizer and loss\n","    optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-3)\n","    criterion = nn.MSELoss()\n","\n","    # Data storage\n","    epoch_data = []\n","    metrics_history = {\n","        'train_loss': [],\n","        'test_mse': [],\n","        'test_psnr': [],\n","        'test_ssim': []\n","    }\n","\n","    # Start training timer\n","    train_start_time = time.time()\n","\n","    for epoch in range(epochs):\n","        epoch_start_time = time.time()\n","        epoch_loss = 0\n","\n","        # Training phase\n","        encoder.train()\n","        decoder.train()\n","\n","        for clean_images, _ in train_loader:\n","            clean_images = clean_images.to(device)\n","\n","            # Add noise based on selected type\n","            if noise_type == 'gaussian':\n","                noisy_images = add_gaussian_noise(clean_images)\n","            elif noise_type == 'salt_pepper':\n","                noisy_images = add_salt_pepper_noise(clean_images)\n","            else:\n","                raise ValueError(f\"Unknown noise type: {noise_type}\")\n","\n","            # Forward pass\n","            z = encoder(noisy_images)\n","            reconstructions = decoder(z)\n","\n","            # Loss calculation (compare to clean images)\n","            loss = criterion(reconstructions, clean_images)\n","\n","            # Backward pass\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            # Accumulate loss\n","            epoch_loss += loss.item()\n","\n","        # Store training loss (averaged per sample)\n","        metrics_history['train_loss'].append(epoch_loss/len(train_loader))\n","\n","        # Evaluation phase\n","        test_start_time = time.time()\n","        test_metrics = evaluate_denoising(encoder, decoder, test_loader, noise_type)\n","        test_time = time.time() - test_start_time\n","\n","        metrics_history['test_mse'].append(test_metrics['mse'])\n","        metrics_history['test_psnr'].append(test_metrics['psnr'])\n","        metrics_history['test_ssim'].append(test_metrics['ssim'])\n","\n","        # Calculate epoch time\n","        epoch_time = time.time() - epoch_start_time\n","\n","        # Store epoch info\n","        epoch_info = {\n","            'epoch': epoch+1,\n","            'train_loss': metrics_history['train_loss'][-1],\n","            'test_mse': metrics_history['test_mse'][-1],\n","            'test_psnr': metrics_history['test_psnr'][-1],\n","            'test_ssim': metrics_history['test_ssim'][-1],\n","            'epoch_time_sec': epoch_time,\n","            'test_time_sec': test_time,\n","            'latent_dim': latent_dim,\n","            'noise_type': noise_type\n","        }\n","        epoch_data.append(epoch_info)\n","\n","        print(f\"Epoch [{epoch+1}/{epochs}]  Time: {epoch_time:.2f}s  \"\n","              f\"Loss: {epoch_info['train_loss']:.4f}  \"\n","              f\"Test MSE: {epoch_info['test_mse']:.4f}  \"\n","              f\"PSNR: {epoch_info['test_psnr']:.2f}dB\")\n","\n","    # Calculate total training time\n","    total_train_time = time.time() - train_start_time\n","\n","    # Save to Excel\n","    df_epochs = pd.DataFrame(epoch_data)\n","    df_epochs.to_excel(writer, sheet_name='training_metrics', index=False)\n","\n","    # Save final metrics\n","    final_metrics = {\n","        'latent_dim': latent_dim,\n","        'noise_type': noise_type,\n","        'final_mse': metrics_history['test_mse'][-1],\n","        'final_psnr': metrics_history['test_psnr'][-1],\n","        'final_ssim': metrics_history['test_ssim'][-1],\n","        'final_train_loss': metrics_history['train_loss'][-1],\n","        'compression_ratio': evaluate_compression(latent_dim)['compression_ratio'],\n","        'bits_per_pixel': evaluate_compression(latent_dim)['bits_per_pixel'],\n","        'total_train_time_sec': total_train_time,\n","        'avg_epoch_time_sec': total_train_time/epochs,\n","        'avg_test_time_sec': sum([x['test_time_sec'] for x in epoch_data])/epochs\n","    }\n","    pd.DataFrame([final_metrics]).to_excel(writer, sheet_name='final_metrics', index=False)\n","\n","    writer.close()\n","    plot_training_progress(metrics_history, latent_dim, noise_type)\n","\n","    # Save model\n","    torch.save({\n","        'encoder_state_dict': encoder.state_dict(),\n","        'decoder_state_dict': decoder.state_dict(),\n","        'latent_dim': latent_dim,\n","        'noise_type': noise_type\n","    }, f'results/dae_{noise_type}_latent{latent_dim}_model.pth')\n","\n","    return encoder, decoder, metrics_history, final_metrics\n","\n","# =============================================\n","# 4. DAE Evaluation Functions\n","# =============================================\n","\n","def evaluate_denoising(encoder, decoder, test_loader, noise_type):\n","    encoder.eval()\n","    decoder.eval()\n","\n","    total_mse = 0.0\n","    total_psnr = 0.0\n","    total_ssim = 0.0\n","    total_samples = 0\n","\n","    with torch.no_grad():\n","        for clean_images, _ in test_loader:\n","            clean_images = clean_images.to(device)\n","\n","            # Add noise\n","            if noise_type == 'gaussian':\n","                noisy_images = add_gaussian_noise(clean_images)\n","            elif noise_type == 'salt_pepper':\n","                noisy_images = add_salt_pepper_noise(clean_images)\n","\n","            # Forward pass\n","            z = encoder(noisy_images)\n","            reconstructions = decoder(z)\n","\n","            # Metrics (compare to clean images)\n","            mse = nn.MSELoss()(reconstructions, clean_images)\n","            total_mse += mse.item() * clean_images.size(0)\n","\n","            max_pixel = 1.0\n","            psnr = 20 * torch.log10(max_pixel / torch.sqrt(mse))\n","            total_psnr += psnr.item() * clean_images.size(0)\n","\n","            ssim_val = ssim(reconstructions, clean_images, data_range=1.0, size_average=False)\n","            total_ssim += ssim_val.sum().item()\n","\n","            total_samples += clean_images.size(0)\n","\n","    return {\n","        'mse': total_mse / total_samples,\n","        'psnr': total_psnr / total_samples,\n","        'ssim': total_ssim / total_samples\n","    }\n","\n","def visualize_denoising(encoder, decoder, test_loader, noise_type, num_samples=5):\n","    encoder.eval()\n","    decoder.eval()\n","\n","    clean_images, _ = next(iter(test_loader))\n","    clean_images = clean_images[:num_samples].to(device)\n","\n","    # Add noise\n","    if noise_type == 'gaussian':\n","        noisy_images = add_gaussian_noise(clean_images)\n","    elif noise_type == 'salt_pepper':\n","        noisy_images = add_salt_pepper_noise(clean_images)\n","\n","    with torch.no_grad():\n","        z = encoder(noisy_images)\n","        reconstructions = decoder(z)\n","\n","    plt.figure(figsize=(12, 6))\n","    for i in range(num_samples):\n","        # Original\n","        plt.subplot(3, num_samples, i+1)\n","        plt.imshow(clean_images[i].cpu().squeeze(), cmap='gray')\n","        plt.title(\"Original\" if i == 0 else \"\")\n","        plt.axis('off')\n","\n","        # Noisy\n","        plt.subplot(3, num_samples, num_samples+i+1)\n","        plt.imshow(noisy_images[i].cpu().squeeze(), cmap='gray')\n","        plt.title(\"Noisy\" if i == 0 else \"\")\n","        plt.axis('off')\n","\n","        # Reconstructed\n","        plt.subplot(3, num_samples, 2*num_samples+i+1)\n","        plt.imshow(reconstructions[i].cpu().squeeze(), cmap='gray')\n","        plt.title(\"Reconstructed\" if i == 0 else \"\")\n","        plt.axis('off')\n","\n","    plt.tight_layout()\n","    plt.savefig(f'results/denoising_{noise_type}_examples.png', dpi=300)\n","    plt.close()\n","\n","def plot_training_progress(metrics, latent_dim, noise_type):\n","    plt.figure(figsize=(15, 5))\n","\n","    # Loss plot\n","    plt.subplot(1, 3, 1)\n","    plt.plot(metrics['train_loss'], label='Training Loss')\n","    plt.title(f'Training Loss ({noise_type} noise)\\nLatent Dim: {latent_dim}')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.grid(True)\n","\n","    # Test metrics\n","    plt.subplot(1, 3, 2)\n","    plt.plot(metrics['test_mse'], label='Test MSE')\n","    plt.title('Test MSE')\n","    plt.xlabel('Epoch')\n","    plt.grid(True)\n","\n","    plt.subplot(1, 3, 3)\n","    plt.plot(metrics['test_psnr'], label='Test PSNR')\n","    plt.title('Test PSNR (dB)')\n","    plt.xlabel('Epoch')\n","    plt.grid(True)\n","\n","    plt.tight_layout()\n","    plt.savefig(f'results/dae_training_progress_{noise_type}.png', dpi=300)\n","    plt.close()\n","\n","def evaluate_compression(latent_dim):\n","    original_size = 28 * 28 * 8  # MNIST pixels * 8 bits\n","    compressed_size = latent_dim * 32  # 32-bit floats\n","    compression_ratio = original_size / compressed_size\n","    bpp = compressed_size / (28 * 28)\n","\n","    return {\n","        'compression_ratio': compression_ratio,\n","        'bits_per_pixel': bpp\n","    }\n","\n","# =============================================\n","# 5. Main Execution\n","# =============================================\n","\n","if __name__ == \"__main__\":\n","    # Configuration\n","    latent_dims_to_test = [32]  # Typically DAEs use larger latent spaces\n","    noise_types = ['gaussian', 'salt_pepper']  # Test both noise types\n","    epochs = 50  # DAEs often need more epochs\n","\n","    all_metrics = {}\n","\n","    for noise_type in noise_types:\n","        for latent_dim in latent_dims_to_test:\n","            print(f\"\\n{'='*50}\")\n","            print(f\"Training DAE with {noise_type} noise, Latent Dim: {latent_dim}\")\n","            print(f\"{'='*50}\")\n","\n","            # Train and evaluate\n","            encoder, decoder, _, final_metrics = train_dae(\n","                epochs=epochs,\n","                latent_dim=latent_dim,\n","                noise_type=noise_type\n","            )\n","            all_metrics[f'{noise_type}_latent{latent_dim}'] = final_metrics\n","\n","            # Visualizations\n","            test_data = datasets.MNIST(root=\"./data\", train=False, transform=transforms.ToTensor())\n","            test_loader = DataLoader(test_data, batch_size=128, shuffle=True)\n","            visualize_denoising(encoder, decoder, test_loader, noise_type)\n","\n","    # Save comparison\n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    df_comparison = pd.DataFrame.from_dict(all_metrics, orient='index')\n","    df_comparison.to_excel(f'results/dae_comparison_{timestamp}.xlsx', index=True)\n","\n","    print(\"\\nDAE Training and evaluation complete!\")\n","    print(\"Results saved in the 'results' directory\")"]},{"cell_type":"code","source":["!pip install pytorch_msssim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5uv0HCsJYe1u","executionInfo":{"status":"ok","timestamp":1768040825832,"user_tz":-330,"elapsed":5191,"user":{"displayName":"Sivakumar S","userId":"04332186060573251169"}},"outputId":"e8f716b3-eca1-424c-92c6-638d76358ccc"},"id":"5uv0HCsJYe1u","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch_msssim\n","  Downloading pytorch_msssim-1.0.0-py3-none-any.whl.metadata (8.0 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from pytorch_msssim) (2.9.0+cu126)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (3.5.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->pytorch_msssim) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->pytorch_msssim) (3.0.3)\n","Downloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\n","Installing collected packages: pytorch_msssim\n","Successfully installed pytorch_msssim-1.0.0\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python [conda env:base] *","language":"python","name":"conda-base-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}