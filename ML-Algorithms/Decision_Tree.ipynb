{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32ad1f87-9d68-4634-ace6-a9da8af17bcb",
   "metadata": {},
   "source": [
    "# Types of Classification\n",
    "\n",
    "## Decision Tree\n",
    "* **Graphical representation** of all the possible solutions to a decision.\n",
    "* **Decisions** are based on some conditions.\n",
    "* **Decision made** can be easily explained.\n",
    "\n",
    "### Example Diagram (Logic Flow)\n",
    "**Root Node:** Am I hungry?\n",
    "* **No** $\\rightarrow$ Go to sleep\n",
    "* **Yes** $\\rightarrow$ *Check Condition:* **Have I $25?**\n",
    "    * **Yes** $\\rightarrow$ Go to restaurant\n",
    "    * **No** $\\rightarrow$ Buy a hamburger\n",
    "\n",
    "---\n",
    "**Other Classification Algorithms listed:**\n",
    "* Random Forest\n",
    "* Naïve Bayes\n",
    "* KNN (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdd6d34-3ca8-4740-a0ab-7dcb718bbe3e",
   "metadata": {},
   "source": [
    "##  Definition of a Decision Tree\n",
    "\n",
    "A decision tree is a graphical representation of all the possible solutions to a decision based on certain conditions.\n",
    "It helps you move from a question or problem to a final decision by following a sequence of logical rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb597399-d8f6-4c79-b4cf-d0244ab78e87",
   "metadata": {},
   "source": [
    "### 1. Key Components of a Decision Tree\n",
    "\n",
    "- **Root Node**\n",
    "The starting point of the tree. It represents the first decision or condition.\n",
    "\n",
    "- **Decision Nodes**\n",
    "Intermediate points where another condition or decision is evaluated.\n",
    "\n",
    "- **Leaf Nodes**\n",
    "Final outcomes or decisions such as yes or no, accept or decline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00c0a01-a06d-4586-ab45-c0c3c2fcd741",
   "metadata": {},
   "source": [
    "### 2. Purpose of a Decision Tree\n",
    "\n",
    "- To simplify complex decisions by breaking them down into smaller steps.\n",
    "\n",
    "- To visually represent choices, conditions, and final outcomes.\n",
    "\n",
    "- To help in decision making, classification, and prediction tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f44d93c-aeca-43fd-b5a2-e5c2ff017fff",
   "metadata": {},
   "source": [
    "### 3. Example from the Image: Should I accept a new job offer\n",
    "\n",
    "The decision tree analyzes the job offer using conditions.\n",
    "\n",
    "- Condition 1: Is the salary at least 50,000?\n",
    "\n",
    "If no, decline offer.\n",
    "\n",
    "If yes, move to next condition.\n",
    "\n",
    "- Condition 2: Is the commute more than 1 hour?\n",
    "\n",
    "If yes, decline offer.\n",
    "\n",
    "If no, move to next condition.\n",
    "\n",
    "- Condition 3: Does the job offer free coffee?\n",
    "\n",
    "If yes, accept offer.\n",
    "\n",
    "If no, decline offer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94101fa5-0693-42f2-8ef1-ecef35f0c743",
   "metadata": {},
   "source": [
    "### 4. Why Decision Trees are Useful\n",
    "\n",
    "- They are easy to read and interpret.\n",
    "\n",
    "- They mimic human decision making.\n",
    "\n",
    "- They work well for both classification and regression problems.\n",
    "\n",
    "- They show step by step how each decision is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc28ab2f-12b8-453b-9df7-0d878a85c80a",
   "metadata": {},
   "source": [
    "# Decision Tree Example: Fruit Classification\n",
    "\n",
    "## Dataset\n",
    "\n",
    "| Color | Diameter | Label |\n",
    "|-------|----------|--------|\n",
    "| Green | 3 | Mango |\n",
    "| Yellow | 3 | Lemon |\n",
    "| Red | 1 | Grape |\n",
    "| Yellow | 3 | Mango |\n",
    "| Red | 1 | Grape |\n",
    "\n",
    "## Root Node\n",
    "\n",
    "Split on: **Diameter ≥ 3**  \n",
    "Information Gain: **0.37**\n",
    "\n",
    "### Left Branch (Diameter < 3)\n",
    "- All samples: Grape  \n",
    "- Leaf: **100 percent Grape**\n",
    "\n",
    "### Right Branch (Diameter ≥ 3)\n",
    "Samples: Mango, Mango, Lemon  \n",
    "Next split: **Color == Yellow**  \n",
    "Information Gain: **0.11**\n",
    "\n",
    "#### Branch 1 (Color not Yellow)\n",
    "- Leaf: **100 percent Mango**\n",
    "\n",
    "#### Branch 2 (Color Yellow)\n",
    "- Mango  \n",
    "- Lemon  \n",
    "- Leaf: **50 percent Mango, 50 percent Lemon**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b133f8-256e-410d-997a-7317982bc6fe",
   "metadata": {},
   "source": [
    "# Decision Tree Terminology\n",
    "\n",
    "## Root Node\n",
    "Represents the entire dataset or population. This node is divided into two or more homogeneous groups.\n",
    "\n",
    "## Parent and Child Nodes\n",
    "The root node is the parent node. Any nodes that emerge from it through splitting are known as child nodes.\n",
    "\n",
    "## Splitting\n",
    "Splitting is the process of dividing a node into sub nodes based on certain conditions. It decides how the dataset gets partitioned.\n",
    "\n",
    "## Branch or Subtree\n",
    "A branch or subtree is formed when a node is split. Each branch represents a possible decision path.\n",
    "\n",
    "## Leaf Node\n",
    "A leaf node (terminal node) represents the final output of the decision tree. It cannot be split further.\n",
    "\n",
    "## Pruning\n",
    "Pruning is the opposite of splitting. It removes unnecessary branches from the tree to prevent overfitting and improve model performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
