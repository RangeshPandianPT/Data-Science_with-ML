{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0ded9bd-f2bd-4740-afdf-171145bd3670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "==================================================\n",
      "Training VAE with Latent Dimension: 5\n",
      "==================================================\n",
      "Epoch [1/20]  Time: 9.17s  Loss: 44.29 (Recon: 38.93, KL: 5.35, Dice: 0.0042)\n",
      "Train PSNR: 13.24dB  Test PSNR: 14.23dB\n",
      "Epoch [2/20]  Time: 8.65s  Loss: 35.72 (Recon: 28.90, KL: 6.81, Dice: 0.0035)\n",
      "Train PSNR: 14.34dB  Test PSNR: 14.55dB\n",
      "Epoch [3/20]  Time: 9.70s  Loss: 34.49 (Recon: 27.32, KL: 7.16, Dice: 0.0034)\n",
      "Train PSNR: 14.58dB  Test PSNR: 14.69dB\n",
      "Epoch [4/20]  Time: 9.32s  Loss: 33.80 (Recon: 26.44, KL: 7.35, Dice: 0.0033)\n",
      "Train PSNR: 14.72dB  Test PSNR: 14.77dB\n",
      "Epoch [5/20]  Time: 9.22s  Loss: 33.27 (Recon: 25.80, KL: 7.47, Dice: 0.0032)\n",
      "Train PSNR: 14.83dB  Test PSNR: 14.89dB\n",
      "Epoch [6/20]  Time: 9.31s  Loss: 32.91 (Recon: 25.30, KL: 7.61, Dice: 0.0032)\n",
      "Train PSNR: 14.92dB  Test PSNR: 15.02dB\n",
      "Epoch [7/20]  Time: 9.47s  Loss: 32.60 (Recon: 24.92, KL: 7.68, Dice: 0.0032)\n",
      "Train PSNR: 14.98dB  Test PSNR: 15.01dB\n",
      "Epoch [8/20]  Time: 9.19s  Loss: 32.33 (Recon: 24.58, KL: 7.75, Dice: 0.0031)\n",
      "Train PSNR: 15.04dB  Test PSNR: 15.13dB\n",
      "Epoch [9/20]  Time: 9.21s  Loss: 32.13 (Recon: 24.31, KL: 7.82, Dice: 0.0031)\n",
      "Train PSNR: 15.09dB  Test PSNR: 15.12dB\n",
      "Epoch [10/20]  Time: 9.04s  Loss: 31.94 (Recon: 24.07, KL: 7.87, Dice: 0.0031)\n",
      "Train PSNR: 15.13dB  Test PSNR: 15.17dB\n",
      "Epoch [11/20]  Time: 9.43s  Loss: 31.76 (Recon: 23.85, KL: 7.91, Dice: 0.0031)\n",
      "Train PSNR: 15.17dB  Test PSNR: 15.20dB\n",
      "Epoch [12/20]  Time: 8.87s  Loss: 31.63 (Recon: 23.67, KL: 7.96, Dice: 0.0031)\n",
      "Train PSNR: 15.20dB  Test PSNR: 15.21dB\n",
      "Epoch [13/20]  Time: 9.02s  Loss: 31.49 (Recon: 23.51, KL: 7.98, Dice: 0.0030)\n",
      "Train PSNR: 15.24dB  Test PSNR: 15.27dB\n",
      "Epoch [14/20]  Time: 9.14s  Loss: 31.38 (Recon: 23.36, KL: 8.02, Dice: 0.0030)\n",
      "Train PSNR: 15.26dB  Test PSNR: 15.28dB\n",
      "Epoch [15/20]  Time: 9.39s  Loss: 31.31 (Recon: 23.24, KL: 8.07, Dice: 0.0030)\n",
      "Train PSNR: 15.29dB  Test PSNR: 15.30dB\n",
      "Epoch [16/20]  Time: 8.63s  Loss: 31.20 (Recon: 23.10, KL: 8.10, Dice: 0.0030)\n",
      "Train PSNR: 15.31dB  Test PSNR: 15.29dB\n",
      "Epoch [17/20]  Time: 8.95s  Loss: 31.12 (Recon: 23.00, KL: 8.12, Dice: 0.0030)\n",
      "Train PSNR: 15.33dB  Test PSNR: 15.34dB\n",
      "Epoch [18/20]  Time: 9.12s  Loss: 31.05 (Recon: 22.88, KL: 8.16, Dice: 0.0030)\n",
      "Train PSNR: 15.35dB  Test PSNR: 15.33dB\n",
      "Epoch [19/20]  Time: 9.13s  Loss: 30.97 (Recon: 22.79, KL: 8.18, Dice: 0.0030)\n",
      "Train PSNR: 15.37dB  Test PSNR: 15.36dB\n",
      "Epoch [20/20]  Time: 9.12s  Loss: 30.91 (Recon: 22.71, KL: 8.20, Dice: 0.0030)\n",
      "Train PSNR: 15.39dB  Test PSNR: 15.39dB\n",
      "\n",
      "==================================================\n",
      "Training VAE with Latent Dimension: 10\n",
      "==================================================\n",
      "Epoch [1/20]  Time: 8.88s  Loss: 44.38 (Recon: 38.19, KL: 6.19, Dice: 0.0041)\n",
      "Train PSNR: 13.36dB  Test PSNR: 14.73dB\n",
      "Epoch [2/20]  Time: 9.57s  Loss: 34.20 (Recon: 24.80, KL: 9.39, Dice: 0.0032)\n",
      "Train PSNR: 15.00dB  Test PSNR: 15.33dB\n",
      "Epoch [3/20]  Time: 9.25s  Loss: 32.72 (Recon: 22.70, KL: 10.01, Dice: 0.0030)\n",
      "Train PSNR: 15.39dB  Test PSNR: 15.57dB\n",
      "Epoch [4/20]  Time: 9.18s  Loss: 32.03 (Recon: 21.68, KL: 10.35, Dice: 0.0030)\n",
      "Train PSNR: 15.59dB  Test PSNR: 15.69dB\n",
      "Epoch [5/20]  Time: 9.25s  Loss: 31.60 (Recon: 21.04, KL: 10.56, Dice: 0.0029)\n",
      "Train PSNR: 15.72dB  Test PSNR: 15.86dB\n",
      "Epoch [6/20]  Time: 9.32s  Loss: 31.27 (Recon: 20.57, KL: 10.70, Dice: 0.0028)\n",
      "Train PSNR: 15.81dB  Test PSNR: 15.88dB\n",
      "Epoch [7/20]  Time: 9.25s  Loss: 31.03 (Recon: 20.22, KL: 10.81, Dice: 0.0028)\n",
      "Train PSNR: 15.89dB  Test PSNR: 15.99dB\n",
      "Epoch [8/20]  Time: 8.70s  Loss: 30.84 (Recon: 19.91, KL: 10.93, Dice: 0.0028)\n",
      "Train PSNR: 15.96dB  Test PSNR: 16.08dB\n",
      "Epoch [9/20]  Time: 8.54s  Loss: 30.68 (Recon: 19.65, KL: 11.02, Dice: 0.0028)\n",
      "Train PSNR: 16.01dB  Test PSNR: 16.11dB\n",
      "Epoch [10/20]  Time: 8.67s  Loss: 30.49 (Recon: 19.45, KL: 11.03, Dice: 0.0027)\n",
      "Train PSNR: 16.06dB  Test PSNR: 16.25dB\n",
      "Epoch [11/20]  Time: 8.49s  Loss: 30.36 (Recon: 19.27, KL: 11.08, Dice: 0.0027)\n",
      "Train PSNR: 16.10dB  Test PSNR: 16.17dB\n",
      "Epoch [12/20]  Time: 8.54s  Loss: 30.23 (Recon: 19.09, KL: 11.14, Dice: 0.0027)\n",
      "Train PSNR: 16.14dB  Test PSNR: 16.14dB\n",
      "Epoch [13/20]  Time: 8.65s  Loss: 30.11 (Recon: 18.94, KL: 11.17, Dice: 0.0027)\n",
      "Train PSNR: 16.17dB  Test PSNR: 16.22dB\n",
      "Epoch [14/20]  Time: 8.66s  Loss: 30.01 (Recon: 18.78, KL: 11.22, Dice: 0.0027)\n",
      "Train PSNR: 16.21dB  Test PSNR: 16.18dB\n",
      "Epoch [15/20]  Time: 9.02s  Loss: 29.91 (Recon: 18.67, KL: 11.24, Dice: 0.0027)\n",
      "Train PSNR: 16.24dB  Test PSNR: 16.34dB\n",
      "Epoch [16/20]  Time: 9.30s  Loss: 29.80 (Recon: 18.54, KL: 11.26, Dice: 0.0027)\n",
      "Train PSNR: 16.27dB  Test PSNR: 16.27dB\n",
      "Epoch [17/20]  Time: 9.18s  Loss: 29.75 (Recon: 18.45, KL: 11.30, Dice: 0.0027)\n",
      "Train PSNR: 16.29dB  Test PSNR: 16.37dB\n",
      "Epoch [18/20]  Time: 8.89s  Loss: 29.65 (Recon: 18.33, KL: 11.32, Dice: 0.0027)\n",
      "Train PSNR: 16.32dB  Test PSNR: 16.43dB\n",
      "Epoch [19/20]  Time: 9.30s  Loss: 29.56 (Recon: 18.24, KL: 11.32, Dice: 0.0026)\n",
      "Train PSNR: 16.34dB  Test PSNR: 16.37dB\n",
      "Epoch [20/20]  Time: 9.29s  Loss: 29.52 (Recon: 18.15, KL: 11.36, Dice: 0.0026)\n",
      "Train PSNR: 16.36dB  Test PSNR: 16.42dB\n",
      "\n",
      "==================================================\n",
      "Training VAE with Latent Dimension: 20\n",
      "==================================================\n",
      "Epoch [1/20]  Time: 8.96s  Loss: 45.31 (Recon: 39.02, KL: 6.28, Dice: 0.0042)\n",
      "Train PSNR: 13.25dB  Test PSNR: 14.66dB\n",
      "Epoch [2/20]  Time: 8.77s  Loss: 34.94 (Recon: 24.71, KL: 10.22, Dice: 0.0032)\n",
      "Train PSNR: 15.02dB  Test PSNR: 15.42dB\n",
      "Epoch [3/20]  Time: 9.23s  Loss: 33.11 (Recon: 22.04, KL: 11.07, Dice: 0.0030)\n",
      "Train PSNR: 15.52dB  Test PSNR: 15.77dB\n",
      "Epoch [4/20]  Time: 8.97s  Loss: 32.24 (Recon: 20.79, KL: 11.45, Dice: 0.0029)\n",
      "Train PSNR: 15.77dB  Test PSNR: 15.92dB\n",
      "Epoch [5/20]  Time: 9.12s  Loss: 31.75 (Recon: 20.02, KL: 11.73, Dice: 0.0028)\n",
      "Train PSNR: 15.93dB  Test PSNR: 16.04dB\n",
      "Epoch [6/20]  Time: 9.10s  Loss: 31.40 (Recon: 19.50, KL: 11.90, Dice: 0.0028)\n",
      "Train PSNR: 16.05dB  Test PSNR: 16.13dB\n",
      "Epoch [7/20]  Time: 8.48s  Loss: 31.15 (Recon: 19.12, KL: 12.03, Dice: 0.0027)\n",
      "Train PSNR: 16.13dB  Test PSNR: 16.23dB\n",
      "Epoch [8/20]  Time: 8.73s  Loss: 30.97 (Recon: 18.84, KL: 12.13, Dice: 0.0027)\n",
      "Train PSNR: 16.20dB  Test PSNR: 16.35dB\n",
      "Epoch [9/20]  Time: 8.94s  Loss: 30.78 (Recon: 18.59, KL: 12.19, Dice: 0.0027)\n",
      "Train PSNR: 16.25dB  Test PSNR: 16.28dB\n",
      "Epoch [10/20]  Time: 8.40s  Loss: 30.66 (Recon: 18.39, KL: 12.26, Dice: 0.0027)\n",
      "Train PSNR: 16.30dB  Test PSNR: 16.38dB\n",
      "Epoch [11/20]  Time: 8.51s  Loss: 30.52 (Recon: 18.23, KL: 12.29, Dice: 0.0027)\n",
      "Train PSNR: 16.34dB  Test PSNR: 16.46dB\n",
      "Epoch [12/20]  Time: 8.90s  Loss: 30.43 (Recon: 18.10, KL: 12.33, Dice: 0.0026)\n",
      "Train PSNR: 16.37dB  Test PSNR: 16.39dB\n",
      "Epoch [13/20]  Time: 8.81s  Loss: 30.36 (Recon: 17.98, KL: 12.37, Dice: 0.0026)\n",
      "Train PSNR: 16.40dB  Test PSNR: 16.46dB\n",
      "Epoch [14/20]  Time: 9.22s  Loss: 30.21 (Recon: 17.87, KL: 12.35, Dice: 0.0026)\n",
      "Train PSNR: 16.43dB  Test PSNR: 16.40dB\n",
      "Epoch [15/20]  Time: 9.21s  Loss: 30.16 (Recon: 17.78, KL: 12.37, Dice: 0.0026)\n",
      "Train PSNR: 16.45dB  Test PSNR: 16.46dB\n",
      "Epoch [16/20]  Time: 8.90s  Loss: 30.05 (Recon: 17.67, KL: 12.38, Dice: 0.0026)\n",
      "Train PSNR: 16.47dB  Test PSNR: 16.45dB\n",
      "Epoch [17/20]  Time: 9.27s  Loss: 29.96 (Recon: 17.58, KL: 12.38, Dice: 0.0026)\n",
      "Train PSNR: 16.50dB  Test PSNR: 16.52dB\n",
      "Epoch [18/20]  Time: 9.22s  Loss: 29.93 (Recon: 17.53, KL: 12.40, Dice: 0.0026)\n",
      "Train PSNR: 16.51dB  Test PSNR: 16.64dB\n",
      "Epoch [19/20]  Time: 8.86s  Loss: 29.87 (Recon: 17.46, KL: 12.41, Dice: 0.0026)\n",
      "Train PSNR: 16.53dB  Test PSNR: 16.54dB\n",
      "Epoch [20/20]  Time: 8.57s  Loss: 29.82 (Recon: 17.40, KL: 12.41, Dice: 0.0026)\n",
      "Train PSNR: 16.54dB  Test PSNR: 16.59dB\n",
      "\n",
      "==================================================\n",
      "Training DAE with gaussian noise, Latent Dim: 32\n",
      "==================================================\n",
      "Epoch [1/50]  Time: 8.78s  Loss: 0.0546  Train PSNR: 12.85dB  Test PSNR: 14.62dB\n",
      "Epoch [2/50]  Time: 8.65s  Loss: 0.0304  Train PSNR: 15.18dB  Test PSNR: 15.72dB\n",
      "Epoch [3/50]  Time: 8.67s  Loss: 0.0248  Train PSNR: 16.06dB  Test PSNR: 16.46dB\n",
      "Epoch [4/50]  Time: 8.51s  Loss: 0.0219  Train PSNR: 16.61dB  Test PSNR: 16.88dB\n",
      "Epoch [5/50]  Time: 8.22s  Loss: 0.0198  Train PSNR: 17.03dB  Test PSNR: 17.25dB\n",
      "Epoch [6/50]  Time: 8.30s  Loss: 0.0184  Train PSNR: 17.36dB  Test PSNR: 17.50dB\n",
      "Epoch [7/50]  Time: 8.07s  Loss: 0.0174  Train PSNR: 17.60dB  Test PSNR: 17.72dB\n",
      "Epoch [8/50]  Time: 8.17s  Loss: 0.0166  Train PSNR: 17.79dB  Test PSNR: 17.89dB\n",
      "Epoch [9/50]  Time: 8.07s  Loss: 0.0161  Train PSNR: 17.94dB  Test PSNR: 18.03dB\n",
      "Epoch [10/50]  Time: 8.14s  Loss: 0.0156  Train PSNR: 18.08dB  Test PSNR: 18.14dB\n",
      "Epoch [11/50]  Time: 8.26s  Loss: 0.0152  Train PSNR: 18.19dB  Test PSNR: 18.26dB\n",
      "Epoch [12/50]  Time: 8.72s  Loss: 0.0149  Train PSNR: 18.29dB  Test PSNR: 18.36dB\n",
      "Epoch [13/50]  Time: 8.94s  Loss: 0.0146  Train PSNR: 18.36dB  Test PSNR: 18.42dB\n",
      "Epoch [14/50]  Time: 8.62s  Loss: 0.0143  Train PSNR: 18.44dB  Test PSNR: 18.47dB\n",
      "Epoch [15/50]  Time: 9.11s  Loss: 0.0141  Train PSNR: 18.51dB  Test PSNR: 18.56dB\n",
      "Epoch [16/50]  Time: 9.12s  Loss: 0.0140  Train PSNR: 18.56dB  Test PSNR: 18.55dB\n",
      "Epoch [17/50]  Time: 8.86s  Loss: 0.0138  Train PSNR: 18.61dB  Test PSNR: 18.61dB\n",
      "Epoch [18/50]  Time: 8.60s  Loss: 0.0136  Train PSNR: 18.65dB  Test PSNR: 18.64dB\n",
      "Epoch [19/50]  Time: 8.34s  Loss: 0.0135  Train PSNR: 18.70dB  Test PSNR: 18.70dB\n",
      "Epoch [20/50]  Time: 5.26s  Loss: 0.0134  Train PSNR: 18.74dB  Test PSNR: 18.73dB\n",
      "Epoch [21/50]  Time: 4.90s  Loss: 0.0133  Train PSNR: 18.77dB  Test PSNR: 18.80dB\n",
      "Epoch [22/50]  Time: 4.87s  Loss: 0.0132  Train PSNR: 18.81dB  Test PSNR: 18.80dB\n",
      "Epoch [23/50]  Time: 4.91s  Loss: 0.0131  Train PSNR: 18.84dB  Test PSNR: 18.81dB\n",
      "Epoch [24/50]  Time: 4.92s  Loss: 0.0130  Train PSNR: 18.87dB  Test PSNR: 18.86dB\n",
      "Epoch [25/50]  Time: 4.84s  Loss: 0.0129  Train PSNR: 18.90dB  Test PSNR: 18.87dB\n",
      "Epoch [26/50]  Time: 4.89s  Loss: 0.0128  Train PSNR: 18.92dB  Test PSNR: 18.86dB\n",
      "Epoch [27/50]  Time: 4.88s  Loss: 0.0127  Train PSNR: 18.95dB  Test PSNR: 18.93dB\n",
      "Epoch [28/50]  Time: 4.97s  Loss: 0.0127  Train PSNR: 18.96dB  Test PSNR: 18.87dB\n",
      "Epoch [29/50]  Time: 4.87s  Loss: 0.0126  Train PSNR: 18.99dB  Test PSNR: 18.97dB\n",
      "Epoch [30/50]  Time: 5.15s  Loss: 0.0126  Train PSNR: 19.00dB  Test PSNR: 18.93dB\n",
      "Epoch [31/50]  Time: 4.92s  Loss: 0.0125  Train PSNR: 19.03dB  Test PSNR: 18.97dB\n",
      "Epoch [32/50]  Time: 4.94s  Loss: 0.0125  Train PSNR: 19.04dB  Test PSNR: 19.00dB\n",
      "Epoch [33/50]  Time: 4.95s  Loss: 0.0124  Train PSNR: 19.06dB  Test PSNR: 18.99dB\n",
      "Epoch [34/50]  Time: 4.92s  Loss: 0.0124  Train PSNR: 19.08dB  Test PSNR: 19.06dB\n",
      "Epoch [35/50]  Time: 4.87s  Loss: 0.0123  Train PSNR: 19.09dB  Test PSNR: 19.03dB\n",
      "Epoch [36/50]  Time: 4.92s  Loss: 0.0123  Train PSNR: 19.11dB  Test PSNR: 19.03dB\n",
      "Epoch [37/50]  Time: 5.02s  Loss: 0.0123  Train PSNR: 19.11dB  Test PSNR: 19.06dB\n",
      "Epoch [38/50]  Time: 4.92s  Loss: 0.0122  Train PSNR: 19.13dB  Test PSNR: 19.08dB\n",
      "Epoch [39/50]  Time: 4.98s  Loss: 0.0122  Train PSNR: 19.14dB  Test PSNR: 19.05dB\n",
      "Epoch [40/50]  Time: 5.07s  Loss: 0.0122  Train PSNR: 19.15dB  Test PSNR: 19.09dB\n",
      "Epoch [41/50]  Time: 5.01s  Loss: 0.0121  Train PSNR: 19.17dB  Test PSNR: 19.08dB\n",
      "Epoch [42/50]  Time: 5.03s  Loss: 0.0121  Train PSNR: 19.17dB  Test PSNR: 19.10dB\n",
      "Epoch [43/50]  Time: 5.03s  Loss: 0.0121  Train PSNR: 19.19dB  Test PSNR: 19.15dB\n",
      "Epoch [44/50]  Time: 5.01s  Loss: 0.0120  Train PSNR: 19.20dB  Test PSNR: 19.14dB\n",
      "Epoch [45/50]  Time: 5.17s  Loss: 0.0120  Train PSNR: 19.21dB  Test PSNR: 19.09dB\n",
      "Epoch [46/50]  Time: 5.16s  Loss: 0.0120  Train PSNR: 19.21dB  Test PSNR: 19.10dB\n",
      "Epoch [47/50]  Time: 5.06s  Loss: 0.0120  Train PSNR: 19.22dB  Test PSNR: 19.17dB\n",
      "Epoch [48/50]  Time: 4.94s  Loss: 0.0119  Train PSNR: 19.23dB  Test PSNR: 19.12dB\n",
      "Epoch [49/50]  Time: 5.01s  Loss: 0.0119  Train PSNR: 19.24dB  Test PSNR: 19.16dB\n",
      "Epoch [50/50]  Time: 5.01s  Loss: 0.0119  Train PSNR: 19.25dB  Test PSNR: 19.14dB\n",
      "\n",
      "==================================================\n",
      "Training DAE with salt_pepper noise, Latent Dim: 32\n",
      "==================================================\n",
      "Epoch [1/50]  Time: 5.40s  Loss: 0.0447  Train PSNR: 13.92dB  Test PSNR: 16.05dB\n",
      "Epoch [2/50]  Time: 5.25s  Loss: 0.0210  Train PSNR: 16.79dB  Test PSNR: 17.55dB\n",
      "Epoch [3/50]  Time: 5.37s  Loss: 0.0166  Train PSNR: 17.80dB  Test PSNR: 18.27dB\n",
      "Epoch [4/50]  Time: 5.48s  Loss: 0.0143  Train PSNR: 18.46dB  Test PSNR: 18.81dB\n",
      "Epoch [5/50]  Time: 5.40s  Loss: 0.0126  Train PSNR: 19.01dB  Test PSNR: 19.31dB\n",
      "Epoch [6/50]  Time: 5.28s  Loss: 0.0115  Train PSNR: 19.40dB  Test PSNR: 19.59dB\n",
      "Epoch [7/50]  Time: 5.07s  Loss: 0.0107  Train PSNR: 19.70dB  Test PSNR: 19.88dB\n",
      "Epoch [8/50]  Time: 5.04s  Loss: 0.0101  Train PSNR: 19.94dB  Test PSNR: 20.02dB\n",
      "Epoch [9/50]  Time: 5.08s  Loss: 0.0097  Train PSNR: 20.14dB  Test PSNR: 20.21dB\n",
      "Epoch [10/50]  Time: 5.16s  Loss: 0.0093  Train PSNR: 20.30dB  Test PSNR: 20.30dB\n",
      "Epoch [11/50]  Time: 5.10s  Loss: 0.0090  Train PSNR: 20.45dB  Test PSNR: 20.49dB\n",
      "Epoch [12/50]  Time: 5.08s  Loss: 0.0088  Train PSNR: 20.56dB  Test PSNR: 20.61dB\n",
      "Epoch [13/50]  Time: 5.14s  Loss: 0.0086  Train PSNR: 20.68dB  Test PSNR: 20.70dB\n",
      "Epoch [14/50]  Time: 5.10s  Loss: 0.0084  Train PSNR: 20.76dB  Test PSNR: 20.79dB\n",
      "Epoch [15/50]  Time: 5.09s  Loss: 0.0082  Train PSNR: 20.85dB  Test PSNR: 20.82dB\n",
      "Epoch [16/50]  Time: 5.02s  Loss: 0.0081  Train PSNR: 20.92dB  Test PSNR: 20.84dB\n",
      "Epoch [17/50]  Time: 4.99s  Loss: 0.0080  Train PSNR: 20.99dB  Test PSNR: 20.87dB\n",
      "Epoch [18/50]  Time: 5.14s  Loss: 0.0079  Train PSNR: 21.05dB  Test PSNR: 21.02dB\n",
      "Epoch [19/50]  Time: 5.21s  Loss: 0.0078  Train PSNR: 21.11dB  Test PSNR: 21.03dB\n",
      "Epoch [20/50]  Time: 5.17s  Loss: 0.0077  Train PSNR: 21.16dB  Test PSNR: 21.09dB\n",
      "Epoch [21/50]  Time: 5.22s  Loss: 0.0076  Train PSNR: 21.21dB  Test PSNR: 21.14dB\n",
      "Epoch [22/50]  Time: 5.11s  Loss: 0.0075  Train PSNR: 21.25dB  Test PSNR: 21.18dB\n",
      "Epoch [23/50]  Time: 5.12s  Loss: 0.0074  Train PSNR: 21.30dB  Test PSNR: 21.23dB\n",
      "Epoch [24/50]  Time: 5.07s  Loss: 0.0074  Train PSNR: 21.33dB  Test PSNR: 21.18dB\n",
      "Epoch [25/50]  Time: 5.22s  Loss: 0.0073  Train PSNR: 21.35dB  Test PSNR: 21.26dB\n",
      "Epoch [26/50]  Time: 5.13s  Loss: 0.0073  Train PSNR: 21.39dB  Test PSNR: 21.30dB\n",
      "Epoch [27/50]  Time: 5.11s  Loss: 0.0072  Train PSNR: 21.41dB  Test PSNR: 21.30dB\n",
      "Epoch [28/50]  Time: 5.15s  Loss: 0.0072  Train PSNR: 21.44dB  Test PSNR: 21.26dB\n",
      "Epoch [29/50]  Time: 5.19s  Loss: 0.0071  Train PSNR: 21.47dB  Test PSNR: 21.32dB\n",
      "Epoch [30/50]  Time: 5.23s  Loss: 0.0071  Train PSNR: 21.50dB  Test PSNR: 21.34dB\n",
      "Epoch [31/50]  Time: 5.07s  Loss: 0.0071  Train PSNR: 21.52dB  Test PSNR: 21.30dB\n",
      "Epoch [32/50]  Time: 5.14s  Loss: 0.0070  Train PSNR: 21.53dB  Test PSNR: 21.37dB\n",
      "Epoch [33/50]  Time: 5.13s  Loss: 0.0070  Train PSNR: 21.56dB  Test PSNR: 21.41dB\n",
      "Epoch [34/50]  Time: 5.32s  Loss: 0.0070  Train PSNR: 21.58dB  Test PSNR: 21.32dB\n",
      "Epoch [35/50]  Time: 5.13s  Loss: 0.0069  Train PSNR: 21.60dB  Test PSNR: 21.43dB\n",
      "Epoch [36/50]  Time: 5.20s  Loss: 0.0069  Train PSNR: 21.62dB  Test PSNR: 21.40dB\n",
      "Epoch [37/50]  Time: 5.06s  Loss: 0.0069  Train PSNR: 21.63dB  Test PSNR: 21.43dB\n",
      "Epoch [38/50]  Time: 5.02s  Loss: 0.0068  Train PSNR: 21.65dB  Test PSNR: 21.46dB\n",
      "Epoch [39/50]  Time: 5.19s  Loss: 0.0068  Train PSNR: 21.67dB  Test PSNR: 21.48dB\n",
      "Epoch [40/50]  Time: 5.21s  Loss: 0.0068  Train PSNR: 21.68dB  Test PSNR: 21.53dB\n",
      "Epoch [41/50]  Time: 5.05s  Loss: 0.0068  Train PSNR: 21.70dB  Test PSNR: 21.48dB\n",
      "Epoch [42/50]  Time: 5.04s  Loss: 0.0068  Train PSNR: 21.71dB  Test PSNR: 21.43dB\n",
      "Epoch [43/50]  Time: 4.96s  Loss: 0.0067  Train PSNR: 21.72dB  Test PSNR: 21.53dB\n",
      "Epoch [44/50]  Time: 5.00s  Loss: 0.0067  Train PSNR: 21.74dB  Test PSNR: 21.55dB\n",
      "Epoch [45/50]  Time: 5.15s  Loss: 0.0067  Train PSNR: 21.75dB  Test PSNR: 21.54dB\n",
      "Epoch [46/50]  Time: 5.01s  Loss: 0.0067  Train PSNR: 21.76dB  Test PSNR: 21.55dB\n",
      "Epoch [47/50]  Time: 5.10s  Loss: 0.0067  Train PSNR: 21.77dB  Test PSNR: 21.60dB\n",
      "Epoch [48/50]  Time: 5.03s  Loss: 0.0066  Train PSNR: 21.78dB  Test PSNR: 21.56dB\n",
      "Epoch [49/50]  Time: 5.09s  Loss: 0.0066  Train PSNR: 21.79dB  Test PSNR: 21.58dB\n",
      "Epoch [50/50]  Time: 4.97s  Loss: 0.0066  Train PSNR: 21.80dB  Test PSNR: 21.55dB\n",
      "\n",
      "Training complete! All results saved in the 'results' directory\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pytorch_msssim import ssim\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# =============================================\n",
    "# 1. Model Definitions (VAE and DAE)\n",
    "# =============================================\n",
    "\n",
    "class VAE_Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=10):\n",
    "        super(VAE_Encoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 400),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_mean = nn.Linear(400, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(400, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        return self.fc_mean(h), self.fc_logvar(h)\n",
    "\n",
    "class VAE_Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=10):\n",
    "        super(VAE_Decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 28*28),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Unflatten(1, (1, 28, 28))\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "class DAE_Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=32):\n",
    "        super(DAE_Encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, latent_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "class DAE_Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=32):\n",
    "        super(DAE_Decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 28*28),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Unflatten(1, (1, 28, 28))\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "# =============================================\n",
    "# 2. Helper Functions\n",
    "# =============================================\n",
    "\n",
    "def dice_loss(preds, targets, epsilon=1e-6):\n",
    "    preds = preds.view(preds.size(0), -1)\n",
    "    targets = targets.view(targets.size(0), -1)\n",
    "    intersection = (preds * targets).sum(dim=1)\n",
    "    union = preds.sum(dim=1) + targets.sum(dim=1)\n",
    "    dice = (2. * intersection + epsilon) / (union + epsilon)\n",
    "    return 1 - dice.mean()\n",
    "\n",
    "def add_gaussian_noise(images, noise_factor=0.5):\n",
    "    noisy = images + torch.randn_like(images) * noise_factor\n",
    "    return torch.clamp(noisy, 0., 1.)\n",
    "\n",
    "def add_salt_pepper_noise(images, prob=0.1):\n",
    "    mask = torch.rand_like(images) < prob\n",
    "    salt = torch.rand_like(images) > 0.5\n",
    "    noisy = images.clone()\n",
    "    noisy[mask] = salt[mask].float()\n",
    "    return noisy\n",
    "\n",
    "def calculate_psnr(mse):\n",
    "    max_pixel = 1.0\n",
    "    if mse == 0:\n",
    "        return 100  # Perfect reconstruction\n",
    "    return 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "\n",
    "def evaluate_compression(latent_dim):\n",
    "    original_size = 28 * 28 * 8  # MNIST pixels * 8 bits\n",
    "    compressed_size = latent_dim * 32  # 32-bit floats\n",
    "    compression_ratio = original_size / compressed_size\n",
    "    bpp = compressed_size / (28 * 28)\n",
    "    return {'compression_ratio': compression_ratio, 'bits_per_pixel': bpp}\n",
    "\n",
    "# =============================================\n",
    "# 3. Training Functions\n",
    "# =============================================\n",
    "\n",
    "def train_vae(epochs=20, batch_size=128, latent_dim=10):\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    excel_filename = f'results/vae_metrics_{timestamp}.xlsx'\n",
    "    writer = pd.ExcelWriter(excel_filename, engine='openpyxl')\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_data = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_data = datasets.MNIST(root=\"./data\", train=False, transform=transform)\n",
    "    test_loader = DataLoader(test_data, batch_size=128, shuffle=True)\n",
    "\n",
    "    encoder = VAE_Encoder(latent_dim).to(device)\n",
    "    decoder = VAE_Decoder(latent_dim).to(device)\n",
    "    optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-3)\n",
    "\n",
    "    metrics_history = {\n",
    "        'total_loss': [], 'recon_loss': [], 'kl_loss': [], 'dice_loss': [],\n",
    "        'train_mse': [], 'train_psnr': [],  # Added training PSNR\n",
    "        'test_mse': [], 'test_psnr': [], 'test_ssim': [], 'test_dice': []\n",
    "    }\n",
    "    epoch_data = []\n",
    "\n",
    "    def reparameterize(mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    train_start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        epoch_recon, epoch_kl, epoch_total, epoch_dice = 0, 0, 0, 0\n",
    "        epoch_train_mse, epoch_train_psnr = 0, 0  # Track training PSNR\n",
    "        \n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        \n",
    "        for images, _ in train_loader:\n",
    "            images = images.to(device)\n",
    "            mu, logvar = encoder(images)\n",
    "            z = reparameterize(mu, logvar)\n",
    "            recon = decoder(z)\n",
    "            \n",
    "            # Calculate losses\n",
    "            recon_loss = nn.MSELoss(reduction='sum')(recon, images)\n",
    "            kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "            dice = dice_loss(recon, images)\n",
    "            total_loss = recon_loss + kl_div + dice\n",
    "            \n",
    "            # Calculate training PSNR\n",
    "            mse = nn.MSELoss(reduction='mean')(recon, images).item()\n",
    "            psnr = calculate_psnr(mse)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate metrics\n",
    "            epoch_recon += recon_loss.item()\n",
    "            epoch_kl += kl_div.item()\n",
    "            epoch_dice += dice.item()\n",
    "            epoch_total += total_loss.item()\n",
    "            epoch_train_mse += mse * images.size(0)\n",
    "            epoch_train_psnr += psnr * images.size(0)\n",
    "\n",
    "        num_samples = len(train_loader.dataset)\n",
    "        metrics_history['recon_loss'].append(epoch_recon/num_samples)\n",
    "        metrics_history['kl_loss'].append(epoch_kl/num_samples)\n",
    "        metrics_history['dice_loss'].append(epoch_dice/num_samples)\n",
    "        metrics_history['total_loss'].append(epoch_total/num_samples)\n",
    "        metrics_history['train_mse'].append(epoch_train_mse/num_samples)\n",
    "        metrics_history['train_psnr'].append(epoch_train_psnr/num_samples)\n",
    "\n",
    "        # Evaluation phase\n",
    "        test_metrics = evaluate_reconstruction(encoder, decoder, test_loader, reparameterize)\n",
    "        for k, v in test_metrics.items():\n",
    "            metrics_history[f'test_{k}'].append(v)\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        epoch_info = {\n",
    "            'epoch': epoch+1,\n",
    "            'total_loss': metrics_history['total_loss'][-1],\n",
    "            'recon_loss': metrics_history['recon_loss'][-1],\n",
    "            'kl_loss': metrics_history['kl_loss'][-1],\n",
    "            'dice_loss': metrics_history['dice_loss'][-1],\n",
    "            'train_mse': metrics_history['train_mse'][-1],\n",
    "            'train_psnr': metrics_history['train_psnr'][-1],\n",
    "            'test_mse': metrics_history['test_mse'][-1],\n",
    "            'test_psnr': metrics_history['test_psnr'][-1],\n",
    "            'test_ssim': metrics_history['test_ssim'][-1],\n",
    "            'test_dice': metrics_history['test_dice'][-1],\n",
    "            'epoch_time_sec': epoch_time,\n",
    "            'latent_dim': latent_dim\n",
    "        }\n",
    "        epoch_data.append(epoch_info)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}]  Time: {epoch_time:.2f}s  \"\n",
    "              f\"Loss: {epoch_info['total_loss']:.2f} (Recon: {epoch_info['recon_loss']:.2f}, \"\n",
    "              f\"KL: {epoch_info['kl_loss']:.2f}, Dice: {epoch_info['dice_loss']:.4f})\\n\"\n",
    "              f\"Train PSNR: {epoch_info['train_psnr']:.2f}dB  Test PSNR: {epoch_info['test_psnr']:.2f}dB\")\n",
    "\n",
    "    total_train_time = time.time() - train_start_time\n",
    "\n",
    "    df_epochs = pd.DataFrame(epoch_data)\n",
    "    df_epochs.to_excel(writer, sheet_name=f'LatentDim_{latent_dim}_epochs', index=False)\n",
    "    \n",
    "    final_metrics = {\n",
    "        'latent_dim': latent_dim,\n",
    "        'final_recon_loss': metrics_history['recon_loss'][-1],\n",
    "        'final_kl_loss': metrics_history['kl_loss'][-1],\n",
    "        'final_dice_loss': metrics_history['dice_loss'][-1],\n",
    "        'final_train_mse': metrics_history['train_mse'][-1],\n",
    "        'final_train_psnr': metrics_history['train_psnr'][-1],\n",
    "        'final_test_mse': metrics_history['test_mse'][-1],\n",
    "        'final_test_psnr': metrics_history['test_psnr'][-1],\n",
    "        'final_test_ssim': metrics_history['test_ssim'][-1],\n",
    "        'final_test_dice': metrics_history['test_dice'][-1],\n",
    "        'total_train_time_sec': total_train_time\n",
    "    }\n",
    "    pd.DataFrame([final_metrics]).to_excel(writer, sheet_name=f'LatentDim_{latent_dim}_final', index=False)\n",
    "    \n",
    "    writer.close()\n",
    "    plot_training_progress(metrics_history, latent_dim, model_type='vae')\n",
    "    visualize_latent_space(encoder, test_loader, reparameterize, latent_dim, model_type='vae')\n",
    "    \n",
    "    torch.save({\n",
    "        'encoder_state_dict': encoder.state_dict(),\n",
    "        'decoder_state_dict': decoder.state_dict(),\n",
    "        'latent_dim': latent_dim\n",
    "    }, f'results/vae_latent{latent_dim}_model.pth')\n",
    "    \n",
    "    return encoder, decoder, metrics_history, final_metrics\n",
    "\n",
    "def train_dae(epochs=50, batch_size=128, latent_dim=32, noise_type='gaussian'):\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    excel_filename = f'results/dae_metrics_{noise_type}_{timestamp}.xlsx'\n",
    "    writer = pd.ExcelWriter(excel_filename, engine='openpyxl')\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_data = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_data = datasets.MNIST(root=\"./data\", train=False, transform=transform)\n",
    "    test_loader = DataLoader(test_data, batch_size=128, shuffle=True)\n",
    "\n",
    "    encoder = DAE_Encoder(latent_dim).to(device)\n",
    "    decoder = DAE_Decoder(latent_dim).to(device)\n",
    "    optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-3)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    metrics_history = {\n",
    "        'train_loss': [], 'train_psnr': [],  # Added training PSNR\n",
    "        'test_mse': [], 'test_psnr': [], 'test_ssim': []\n",
    "    }\n",
    "    epoch_data = []\n",
    "\n",
    "    train_start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        epoch_loss, epoch_psnr = 0, 0  # Track training PSNR\n",
    "        \n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        \n",
    "        for clean_images, _ in train_loader:\n",
    "            clean_images = clean_images.to(device)\n",
    "            \n",
    "            if noise_type == 'gaussian':\n",
    "                noisy_images = add_gaussian_noise(clean_images)\n",
    "            elif noise_type == 'salt_pepper':\n",
    "                noisy_images = add_salt_pepper_noise(clean_images)\n",
    "            \n",
    "            z = encoder(noisy_images)\n",
    "            reconstructions = decoder(z)\n",
    "            loss = criterion(reconstructions, clean_images)\n",
    "            \n",
    "            # Calculate training PSNR\n",
    "            mse = loss.item()\n",
    "            psnr = calculate_psnr(mse)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_psnr += psnr * clean_images.size(0)\n",
    "\n",
    "        metrics_history['train_loss'].append(epoch_loss/len(train_loader))\n",
    "        metrics_history['train_psnr'].append(epoch_psnr/len(train_loader.dataset))\n",
    "        \n",
    "        test_metrics = evaluate_denoising(encoder, decoder, test_loader, noise_type)\n",
    "        metrics_history['test_mse'].append(test_metrics['mse'])\n",
    "        metrics_history['test_psnr'].append(test_metrics['psnr'])\n",
    "        metrics_history['test_ssim'].append(test_metrics['ssim'])\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        epoch_info = {\n",
    "            'epoch': epoch+1,\n",
    "            'train_loss': metrics_history['train_loss'][-1],\n",
    "            'train_psnr': metrics_history['train_psnr'][-1],\n",
    "            'test_mse': metrics_history['test_mse'][-1],\n",
    "            'test_psnr': metrics_history['test_psnr'][-1],\n",
    "            'test_ssim': metrics_history['test_ssim'][-1],\n",
    "            'epoch_time_sec': epoch_time,\n",
    "            'latent_dim': latent_dim,\n",
    "            'noise_type': noise_type\n",
    "        }\n",
    "        epoch_data.append(epoch_info)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}]  Time: {epoch_time:.2f}s  \"\n",
    "              f\"Loss: {epoch_info['train_loss']:.4f}  \"\n",
    "              f\"Train PSNR: {epoch_info['train_psnr']:.2f}dB  \"\n",
    "              f\"Test PSNR: {epoch_info['test_psnr']:.2f}dB\")\n",
    "\n",
    "    total_train_time = time.time() - train_start_time\n",
    "\n",
    "    df_epochs = pd.DataFrame(epoch_data)\n",
    "    df_epochs.to_excel(writer, sheet_name='training_metrics', index=False)\n",
    "    \n",
    "    final_metrics = {\n",
    "        'latent_dim': latent_dim,\n",
    "        'noise_type': noise_type,\n",
    "        'final_train_loss': metrics_history['train_loss'][-1],\n",
    "        'final_train_psnr': metrics_history['train_psnr'][-1],\n",
    "        'final_test_mse': metrics_history['test_mse'][-1],\n",
    "        'final_test_psnr': metrics_history['test_psnr'][-1],\n",
    "        'final_test_ssim': metrics_history['test_ssim'][-1],\n",
    "        'compression_ratio': evaluate_compression(latent_dim)['compression_ratio'],\n",
    "        'bits_per_pixel': evaluate_compression(latent_dim)['bits_per_pixel'],\n",
    "        'total_train_time_sec': total_train_time\n",
    "    }\n",
    "    pd.DataFrame([final_metrics]).to_excel(writer, sheet_name='final_metrics', index=False)\n",
    "    \n",
    "    writer.close()\n",
    "    plot_training_progress(metrics_history, latent_dim, model_type='dae')\n",
    "    visualize_latent_space(encoder, test_loader, lambda x: x, latent_dim, model_type='dae')\n",
    "    \n",
    "    torch.save({\n",
    "        'encoder_state_dict': encoder.state_dict(),\n",
    "        'decoder_state_dict': decoder.state_dict(),\n",
    "        'latent_dim': latent_dim,\n",
    "        'noise_type': noise_type\n",
    "    }, f'results/dae_{noise_type}_latent{latent_dim}_model.pth')\n",
    "    \n",
    "    return encoder, decoder, metrics_history, final_metrics\n",
    "\n",
    "# =============================================\n",
    "# 4. Evaluation and Visualization Functions\n",
    "# =============================================\n",
    "\n",
    "def evaluate_reconstruction(encoder, decoder, test_loader, reparameterize_fn):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    total_mse, total_psnr, total_ssim, total_dice = 0.0, 0.0, 0.0, 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, _ in test_loader:\n",
    "            images = images.to(device)\n",
    "            mu, logvar = encoder(images)\n",
    "            z = reparameterize_fn(mu, logvar)\n",
    "            reconstructions = decoder(z)\n",
    "            \n",
    "            mse = nn.MSELoss()(reconstructions, images)\n",
    "            psnr = calculate_psnr(mse.item())\n",
    "            ssim_val = ssim(reconstructions, images, data_range=1.0, size_average=False)\n",
    "            dice = dice_loss(reconstructions, images)\n",
    "            \n",
    "            total_mse += mse.item() * images.size(0)\n",
    "            total_psnr += psnr * images.size(0)\n",
    "            total_ssim += ssim_val.sum().item()\n",
    "            total_dice += dice.item() * images.size(0)\n",
    "            total_samples += images.size(0)\n",
    "    \n",
    "    return {\n",
    "        'mse': total_mse / total_samples,\n",
    "        'psnr': total_psnr / total_samples,\n",
    "        'ssim': total_ssim / total_samples,\n",
    "        'dice': total_dice / total_samples\n",
    "    }\n",
    "\n",
    "def evaluate_denoising(encoder, decoder, test_loader, noise_type):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    total_mse, total_psnr, total_ssim = 0.0, 0.0, 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for clean_images, _ in test_loader:\n",
    "            clean_images = clean_images.to(device)\n",
    "            \n",
    "            if noise_type == 'gaussian':\n",
    "                noisy_images = add_gaussian_noise(clean_images)\n",
    "            elif noise_type == 'salt_pepper':\n",
    "                noisy_images = add_salt_pepper_noise(clean_images)\n",
    "            \n",
    "            z = encoder(noisy_images)\n",
    "            reconstructions = decoder(z)\n",
    "            \n",
    "            mse = nn.MSELoss()(reconstructions, clean_images)\n",
    "            psnr = calculate_psnr(mse.item())\n",
    "            ssim_val = ssim(reconstructions, clean_images, data_range=1.0, size_average=False)\n",
    "            \n",
    "            total_mse += mse.item() * clean_images.size(0)\n",
    "            total_psnr += psnr * clean_images.size(0)\n",
    "            total_ssim += ssim_val.sum().item()\n",
    "            total_samples += clean_images.size(0)\n",
    "    \n",
    "    return {\n",
    "        'mse': total_mse / total_samples,\n",
    "        'psnr': total_psnr / total_samples,\n",
    "        'ssim': total_ssim / total_samples\n",
    "    }\n",
    "\n",
    "def visualize_latent_space(encoder, test_loader, reparameterize_fn, latent_dim, model_type='vae'):\n",
    "    encoder.eval()\n",
    "    latents = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, label in test_loader:\n",
    "            images = images.to(device)\n",
    "            if model_type == 'vae':\n",
    "                mu, logvar = encoder(images)\n",
    "                z = reparameterize_fn(mu, logvar)\n",
    "            else:  # DAE\n",
    "                z = encoder(images)\n",
    "            latents.append(z.cpu())\n",
    "            labels.append(label)\n",
    "    \n",
    "    latents = torch.cat(latents).numpy()\n",
    "    labels = torch.cat(labels).numpy()\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # t-SNE visualization\n",
    "    if latent_dim >= 2:\n",
    "        tsne = TSNE(n_components=2)\n",
    "        latents_2d = tsne.fit_transform(latents)\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.scatter(latents_2d[:, 0], latents_2d[:, 1], c=labels, cmap='tab10', alpha=0.6)\n",
    "        plt.colorbar(ticks=range(10))\n",
    "        plt.title('t-SNE Projection')\n",
    "    \n",
    "    # Dimension distributions\n",
    "    plt.subplot(1, 3, 2)\n",
    "    for dim in range(min(3, latent_dim)):\n",
    "        plt.hist(latents[:, dim], bins=50, alpha=0.5, label=f'Dim {dim+1}')\n",
    "    plt.title('Latent Dimension Distributions')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Statistics\n",
    "    plt.subplot(1, 3, 3)\n",
    "    dim_means = np.mean(latents, axis=0)\n",
    "    dim_vars = np.var(latents, axis=0)\n",
    "    plt.bar(range(latent_dim), dim_means, alpha=0.5, label='Mean')\n",
    "    plt.bar(range(latent_dim), dim_vars, alpha=0.5, label='Variance')\n",
    "    plt.title('Latent Dimension Statistics')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.suptitle(f'{model_type.upper()} Latent Space (Dim={latent_dim})')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'results/{model_type}_latent_space_latent{latent_dim}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def plot_training_progress(metrics, latent_dim, model_type='vae'):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    if model_type == 'vae':\n",
    "        plt.subplot(1, 4, 1)\n",
    "        plt.plot(metrics['total_loss'], label='Total Loss')\n",
    "        plt.plot(metrics['recon_loss'], label='Recon Loss')\n",
    "        plt.plot(metrics['kl_loss'], label='KL Loss')\n",
    "        plt.plot(metrics['dice_loss'], label='Dice Loss')\n",
    "        plt.title('Training Losses')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(1, 4, 2)\n",
    "        plt.plot(metrics['train_psnr'], label='Train PSNR')\n",
    "        plt.plot(metrics['test_psnr'], label='Test PSNR')\n",
    "        plt.title('PSNR (dB)')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(1, 4, 3)\n",
    "        plt.plot(metrics['test_mse'], label='Test MSE')\n",
    "        plt.title('Test MSE')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(1, 4, 4)\n",
    "        plt.plot(metrics['test_ssim'], label='Test SSIM')\n",
    "        plt.title('Test SSIM')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.grid(True)\n",
    "    else:  # DAE\n",
    "        plt.subplot(1, 4, 1)\n",
    "        plt.plot(metrics['train_loss'], label='Training Loss')\n",
    "        plt.title('Training Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(1, 4, 2)\n",
    "        plt.plot(metrics['train_psnr'], label='Train PSNR')\n",
    "        plt.plot(metrics['test_psnr'], label='Test PSNR')\n",
    "        plt.title('PSNR (dB)')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(1, 4, 3)\n",
    "        plt.plot(metrics['test_mse'], label='Test MSE')\n",
    "        plt.title('Test MSE')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(1, 4, 4)\n",
    "        plt.plot(metrics['test_ssim'], label='Test SSIM')\n",
    "        plt.title('Test SSIM')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.grid(True)\n",
    "    \n",
    "    plt.suptitle(f'{model_type.upper()} Training Progress (Latent Dim={latent_dim})')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'results/{model_type}_training_progress_latent{latent_dim}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def visualize_reconstructions(encoder, decoder, test_loader, reparameterize_fn, num_samples=5, model_type='vae'):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    images, _ = next(iter(test_loader))\n",
    "    images = images[:num_samples].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if model_type == 'vae':\n",
    "            mu, logvar = encoder(images)\n",
    "            z = reparameterize_fn(mu, logvar)\n",
    "        else:  # DAE\n",
    "            z = encoder(images)\n",
    "        reconstructions = decoder(z)\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(2, num_samples, i+1)\n",
    "        plt.imshow(images[i].cpu().squeeze(), cmap='gray')\n",
    "        plt.title(\"Original\" if i == 0 else \"\")\n",
    "        plt.axis('off')\n",
    "        plt.subplot(2, num_samples, num_samples+i+1)\n",
    "        plt.imshow(reconstructions[i].cpu().squeeze(), cmap='gray')\n",
    "        plt.title(\"Reconstructed\" if i == 0 else \"\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle(f'{model_type.upper()} Reconstructions')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'results/{model_type}_reconstructions_latent{latent_dim}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# =============================================\n",
    "# 5. Main Execution\n",
    "# =============================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # VAE Configuration\n",
    "    vae_latent_dims = [5, 10, 20]\n",
    "    vae_metrics = {}\n",
    "    \n",
    "    # DAE Configuration\n",
    "    dae_latent_dims = [32]\n",
    "    noise_types = ['gaussian', 'salt_pepper']\n",
    "    dae_metrics = {}\n",
    "    \n",
    "    # Train VAEs\n",
    "    for latent_dim in vae_latent_dims:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Training VAE with Latent Dimension: {latent_dim}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        encoder, decoder, _, final_metrics = train_vae(latent_dim=latent_dim)\n",
    "        vae_metrics[f'LatentDim={latent_dim}'] = final_metrics\n",
    "        \n",
    "        test_data = datasets.MNIST(root=\"./data\", train=False, transform=transforms.ToTensor())\n",
    "        test_loader = DataLoader(test_data, batch_size=128, shuffle=True)\n",
    "        visualize_reconstructions(encoder, decoder, test_loader, \n",
    "                                lambda mu, logvar: mu + torch.exp(0.5*logvar) * torch.randn_like(logvar),\n",
    "                                model_type='vae')\n",
    "    \n",
    "    # Train DAEs\n",
    "    for noise_type in noise_types:\n",
    "        for latent_dim in dae_latent_dims:\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Training DAE with {noise_type} noise, Latent Dim: {latent_dim}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            encoder, decoder, _, final_metrics = train_dae(latent_dim=latent_dim, noise_type=noise_type)\n",
    "            dae_metrics[f'{noise_type}_latent{latent_dim}'] = final_metrics\n",
    "            \n",
    "            test_data = datasets.MNIST(root=\"./data\", train=False, transform=transforms.ToTensor())\n",
    "            test_loader = DataLoader(test_data, batch_size=128, shuffle=True)\n",
    "            visualize_reconstructions(encoder, decoder, test_loader, \n",
    "                                    lambda x: x,  # Identity function for DAE\n",
    "                                    model_type='dae')\n",
    "    \n",
    "    # Save comparison results\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    with pd.ExcelWriter(f'results/model_comparison_{timestamp}.xlsx', engine='openpyxl') as writer:\n",
    "        pd.DataFrame.from_dict(vae_metrics, orient='index').to_excel(writer, sheet_name='VAE_Results')\n",
    "        pd.DataFrame.from_dict(dae_metrics, orient='index').to_excel(writer, sheet_name='DAE_Results')\n",
    "    \n",
    "    print(\"\\nTraining complete! All results saved in the 'results' directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be2b93d-de90-4f96-b429-e7271e4de70f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
