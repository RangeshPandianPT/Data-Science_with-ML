{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33ec6405-f3ea-4934-aee6-3c49f4f27a6c",
   "metadata": {},
   "source": [
    "## How Convolutional Neural Networks (CNN) Work\n",
    "\n",
    "- **A Convolutional Neural Network (CNN) is a type of deep learning model mainly used for image recognition and computer vision tasks such as handwritten digit recognition, object detection, and image classification.**\n",
    "\n",
    "- CNNs automatically learn spatial features from images using convolution operations instead of manual feature extraction.\n",
    "\n",
    "### Basic Workflow of a CNN\n",
    "\n",
    "**Input Image → Feature Extraction → Classification → Output Label**\n",
    "\n",
    "**Example:**\n",
    "\n",
    "- Image of X → CNN → Output = X\n",
    "\n",
    "- Image of O → CNN → Output = O\n",
    "\n",
    "### Main Layers in a Convolutional Neural Network\n",
    "1. Convolution Layer\n",
    "\n",
    "- Applies filters (kernels) to the input image.\n",
    "\n",
    "- Extracts important features such as:\n",
    "\n",
    "-- Edges\n",
    "\n",
    "-- Corners\n",
    "\n",
    "-- Curves\n",
    "\n",
    "-- Textures\n",
    "\n",
    "- Each filter slides over the image and produces a feature map.\n",
    "\n",
    "**Key points:**\n",
    "\n",
    "- Preserves spatial relationships\n",
    "\n",
    "- Reduces number of parameters\n",
    "\n",
    "- Learns features automatically\n",
    "\n",
    "2. ReLU Layer (Rectified Linear Unit)\n",
    "\n",
    "- Activation function applied after convolution.\n",
    "\n",
    "- Introduces non-linearity into the model.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "**ReLU(x) = max(0, x)**\n",
    "\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "- Removes negative values\n",
    "\n",
    "- Speeds up training\n",
    "\n",
    "- Helps CNN learn complex patterns\n",
    "\n",
    "3. Pooling Layer\n",
    "\n",
    "- Reduces the spatial size of feature maps.\n",
    "\n",
    "**Common types:**\n",
    "\n",
    "- Max Pooling\n",
    "\n",
    "- Average Pooling\n",
    "\n",
    "**Advantages:**\n",
    "\n",
    "- Reduces computation\n",
    "\n",
    "- Controls overfitting\n",
    "\n",
    "- Makes the model invariant to small image shifts\n",
    "\n",
    "**Example:**\n",
    "\n",
    "- 2×2 Max Pooling selects the maximum value from each block\n",
    "\n",
    "4. Fully Connected Layer\n",
    "\n",
    "- Flattened feature maps are fed into dense neural network layers.\n",
    "\n",
    "- Performs classification based on learned features.\n",
    "\n",
    "**Function:**\n",
    "\n",
    "- Combines all extracted features\n",
    "\n",
    "- Produces final output probabilities or class labels\n",
    "\n",
    "CNN Classification Example\n",
    "Input Image\tCNN Output\n",
    "Handwritten X\tX\n",
    "Handwritten O\tO\n",
    "\n",
    "**The CNN learns distinguishing features:**\n",
    "\n",
    "- Sharp crossing lines → X\n",
    "\n",
    "- Closed circular shape → O\n",
    "\n",
    "**Why CNNs Are Powerful**\n",
    "\n",
    "- Automatic feature extraction\n",
    "\n",
    "- Fewer parameters than traditional neural networks\n",
    "\n",
    "- High accuracy for image-based problems\n",
    "\n",
    "- Works well with large datasets\n",
    "\n",
    "**Common Applications of CNN**\n",
    "\n",
    "- Handwritten digit recognition (MNIST)\n",
    "\n",
    "- Face recognition\n",
    "\n",
    "- Medical image analysis\n",
    "\n",
    "- Object detection\n",
    "\n",
    "- Autonomous vehicles\n",
    "\n",
    "**Summary**\n",
    "\n",
    "- CNNs use convolution, activation, pooling, and fully connected layers\n",
    "\n",
    "- They learn features directly from images\n",
    "\n",
    "- Ideal for computer vision and image classification tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75fedb4-5ce2-46c1-9c8d-bdb147ec7ab2",
   "metadata": {},
   "source": [
    "## Simple CNN Demo Using Python (Image Classification)\n",
    "### Problem\n",
    "\n",
    "#### Classify handwritten digits using a Convolutional Neural Network (CNN).\n",
    "\n",
    "**We will use the MNIST dataset, which contains images of digits from 0 to 9.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0f56c1-3c24-4905-a5ee-982bbb54b943",
   "metadata": {},
   "source": [
    "## Step 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c507a151-2968-4fc6-9c4a-ba78e283b456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ed206f-db86-4cd6-a8ac-75c4ec88a72a",
   "metadata": {},
   "source": [
    "## Explanation:\n",
    "\n",
    "- tensorflow.keras provides CNN layers\n",
    "\n",
    "- matplotlib is used for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5951b90c-d566-44a8-abbc-b99b3b8b608b",
   "metadata": {},
   "source": [
    "## Step 2. Load the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c148c870-dec9-4591-a863-5132e9eb3601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21885d82-face-49f5-b754-3b4d832d8463",
   "metadata": {},
   "source": [
    "## Explanation:\n",
    "\n",
    "- Images are 28×28 grayscale\n",
    "\n",
    "- Labels range from 0 to 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278c25b8-0ecb-49f9-a889-5dc9108aee49",
   "metadata": {},
   "source": [
    "## Step 3. Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e1562f-a0c6-47ab-80ba-62a98b0f9516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Reshape data for CNN (samples, height, width, channels)\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7e8f76-1421-444c-a3f1-cdb17bc3820a",
   "metadata": {},
   "source": [
    "## Explanation:\n",
    "\n",
    "- Normalization improves learning\n",
    "\n",
    "- CNN expects 4D input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7eade2-69dc-4add-8936-5001ff06f636",
   "metadata": {},
   "source": [
    "## Step 4. Build a Simple CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "272c4a47-e7aa-4984-86b0-aa40468f58a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3a1fc3-bf88-4025-9ccb-d84abbde5c8c",
   "metadata": {},
   "source": [
    "## Explanation:\n",
    "\n",
    "- Conv2D extracts image features\n",
    "\n",
    "- MaxPooling2D reduces size\n",
    "\n",
    "- Flatten converts data to 1D\n",
    "\n",
    "- Dense layers perform classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704d8285-562a-46bc-aa16-9b49e2a82550",
   "metadata": {},
   "source": [
    "## Step 5. Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18d82658-2a5f-46a6-962a-d4d4bc7e131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47081f14-d702-450c-a38a-dce386e2cd33",
   "metadata": {},
   "source": [
    "## Explanation:\n",
    "\n",
    "- Adam optimizer adjusts weights\n",
    "\n",
    "- Cross-entropy loss is used for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee53336-7581-4299-a71d-7a3dfb7da543",
   "metadata": {},
   "source": [
    "## Step 6. Train the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2606a17-4ddb-4835-99eb-8d33e34aeb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 15ms/step - accuracy: 0.7550 - loss: 0.7573 - val_accuracy: 0.9123 - val_loss: 0.2958\n",
      "Epoch 2/3\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.9062 - loss: 0.3077 - val_accuracy: 0.9430 - val_loss: 0.2023\n",
      "Epoch 3/3\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.9350 - loss: 0.2102 - val_accuracy: 0.9585 - val_loss: 0.1488\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=3,\n",
    "    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dd6c2c-3377-48a6-af93-867ce43bb282",
   "metadata": {},
   "source": [
    "## Explanation:\n",
    "\n",
    "- Model learns patterns from images\n",
    "\n",
    "- Fewer epochs for quick understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2a8f95-6698-4dbb-96ef-57df00b9b79c",
   "metadata": {},
   "source": [
    "## Step 7. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23160d7e-d012-4981-854a-54e819734667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9466 - loss: 0.1660\n",
      "Test Accuracy: 0.9466000199317932\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657102f9-aeee-4571-97f2-5e36a1974f81",
   "metadata": {},
   "source": [
    "## Step 8. Predict a Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b393bc7f-d3f7-404f-a010-89467f470bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
      "Predicted Label: 7\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_test[0].reshape(28, 28), cmap='gray')\n",
    "plt.title(\"Actual Label: \" + str(y_test[0]))\n",
    "plt.show()\n",
    "\n",
    "prediction = model.predict(X_test[:1])\n",
    "print(\"Predicted Label:\", prediction.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68812ea5-2b8f-402b-95fe-a2cd0ff525f9",
   "metadata": {},
   "source": [
    "## How This Demo Uses CNN Concepts\n",
    "\n",
    "| CNN Concept        | Used Here           |\n",
    "| ------------------ | ------------------- |\n",
    "| Convolution        | Conv2D layers       |\n",
    "| ReLU               | Activation function |\n",
    "| Pooling            | MaxPooling2D        |\n",
    "| Feature Extraction | Convolution layers  |\n",
    "| Classification     | Dense + Softmax     |\n",
    "| Backpropagation    | Automatic           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bc5ccf-b24a-4671-8d5b-5bb850e3ec70",
   "metadata": {},
   "source": [
    "## Key Takeaway\n",
    "\n",
    "- CNNs automatically learn image features\n",
    "\n",
    "- Convolution replaces manual feature extraction\n",
    "\n",
    "- Even a small CNN can achieve high accuracy\n",
    "\n",
    "- This is the foundation for real-world vision systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb912d73-24e9-4d92-a624-3ac44afd5557",
   "metadata": {},
   "source": [
    "# The End !!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
